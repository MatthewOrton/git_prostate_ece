{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('precision', 3)\n",
    "from itertools import compress\n",
    "import copy, sys, os, warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from pyirr import intraclass_correlation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold, RepeatedStratifiedKFold, permutation_test_score, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, roc_curve, confusion_matrix, make_scorer\n",
    "from scipy.stats import spearmanr, mannwhitneyu\n",
    "from compare_auc_delong import delong_roc_test\n",
    "import shap\n",
    "\n",
    "oldPath = os.path.join(os.path.expanduser('~'), 'Documents/GitHub/icrpythonradiomics/machineLearning')\n",
    "if os.path.exists(oldPath):\n",
    "    sys.path.remove(oldPath)\n",
    "sys.path.append(os.path.join(os.path.expanduser('~'), 'Documents/git/git_icrpythonradiomics/machineLearning'))\n",
    "from featureSelection import featureSelection_correlation as featSelCorr\n",
    "\n",
    "dataFolder = os.path.join(os.path.expanduser('~'), 'Dropbox (ICR)/CLINMAG/Radiomics/ECE_Prostate_Semantic')\n",
    "\n",
    "# validation parameters\n",
    "n_splits = 10\n",
    "n_repeats = 100\n",
    "\n",
    "permutationTest = True\n",
    "n_permutations = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def confusion_matrix_thresholds(yTrue, yScore, thresholds):\n",
    "    tnArr, fpArr, fnArr, tpArr = [], [], [], []\n",
    "    nSamples = len(yTrue)\n",
    "    for thresh in thresholds:\n",
    "        tn, fp, fn, tp = confusion_matrix(yTrue, yScore>thresh).ravel()\n",
    "        tnArr.append(tn)\n",
    "        fpArr.append(fp)\n",
    "        fnArr.append(fn)\n",
    "        tpArr.append(tp)\n",
    "    return np.array(tnArr), np.array(fpArr), np.array(fnArr), np.array(tpArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def calculate_fnr(y_true, y_pred, pt=0):\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred > pt).ravel()\n",
    "    return fn/(fn + tp)\n",
    "\n",
    "\n",
    "def calculate_fpr(y_true, y_pred, pt=0):\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred > pt).ravel()\n",
    "    return fp/(fp + tn)\n",
    "\n",
    "\n",
    "def calculate_net_benefit_score(y_true, y_pred, pt=0):\n",
    "    _, fp, _, tp = confusion_matrix(y_true, y_pred > pt).ravel()\n",
    "    net_benefit = (tp - fp * (pt / (1 - pt))) / len(y_true)\n",
    "    return net_benefit\n",
    "\n",
    "\n",
    "def unpack_scorers(cvr):\n",
    "\n",
    "    thresh_FNR, thresh_FPR, thresh_DCA, value_DCA, value_FNR, value_FPR = [], [], [], [], [], []\n",
    "    \n",
    "    for key, value in cvr.items():\n",
    "        if 'test_FNR' in key:\n",
    "            thresh_FNR.append(float(key.replace('test_FNR_','')))\n",
    "            value_FNR.append(np.mean(value))\n",
    "        if 'test_FPR' in key:\n",
    "            thresh_FPR.append(float(key.replace('test_FPR_','')))\n",
    "            value_FPR.append(np.mean(value))\n",
    "        if 'test_DCA' in key:\n",
    "            thresh_DCA.append(float(key.replace('test_DCA_','')))\n",
    "            value_DCA.append(np.mean(value))\n",
    "\n",
    "    idxFNR = np.argsort(thresh_FNR)\n",
    "    idxFPR = np.argsort(thresh_FPR)\n",
    "    idxDCA = np.argsort(thresh_DCA)\n",
    "\n",
    "    FNR = {'thresholds': [thresh_FNR[idx] for idx in idxFNR],\n",
    "           'values': [value_FNR[idx] for idx in idxFNR]}\n",
    "    \n",
    "    FPR = {'thresholds': [thresh_FPR[idx] for idx in idxFPR],\n",
    "           'values': [value_FPR[idx] for idx in idxFPR]}\n",
    "\n",
    "    DCA = {'thresholds': [thresh_DCA[idx] for idx in idxDCA],\n",
    "           'values': [value_DCA[idx] for idx in idxDCA]}\n",
    "    \n",
    "    return FNR, FPR, DCA\n",
    "\n",
    "# Make dictionary of scorers, each of which will compute one point on the FNR and FPR curves.\n",
    "# The dictionary key is used to keep track of the threshold value that was used.\n",
    "scorers = {}\n",
    "\n",
    "# Don't use 0 and 1 as endpoints as this causes numerical underflow.\n",
    "ptArr = np.round(np.linspace(0, 1, 101),2)\n",
    "ptArr[0] = np.round(0.0001,4)\n",
    "ptArr[-1] = np.round(0.9999,4)\n",
    "\n",
    "for pt in ptArr:\n",
    "    scorers['FNR_' + str(pt)] = make_scorer(calculate_fnr, pt = pt, needs_proba=True)\n",
    "    scorers['FPR_' + str(pt)] = make_scorer(calculate_fpr, pt = pt, needs_proba=True)\n",
    "    scorers['DCA_' + str(pt)] = make_scorer(calculate_net_benefit_score, pt = pt, needs_proba=True)\n",
    "\n",
    "# standard scorers    \n",
    "scorers['roc_auc'] = 'roc_auc'\n",
    "scorers['accuracy'] = 'accuracy'\n",
    "scorers['f1'] = 'f1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load two reader semantic data (for computing ICCs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "twoReaderFile = os.path.join(dataFolder, 'ECE_Semantic_Data', 'GG_MG.xlsx')\n",
    "\n",
    "# read spreadsheet\n",
    "df = pd.read_excel(twoReaderFile, sheet_name='GG_MG', engine='openpyxl')\n",
    "\n",
    "# remove features, as with the discovery/test data\n",
    "df.drop(['IndexLesion_GG', 'IndexLesionMG', 'GlobalStageGG', 'GlobalStageMG'], axis=1, inplace=True)\n",
    "\n",
    "# remove rows with missing data - need to check that this leaves the same patients for dfGG as in the discovery data set\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# split to each reader\n",
    "dfGG = df.filter(regex = 'GG|PID', axis = 1)\n",
    "dfMG = df.filter(regex='MG|PID', axis=1)\n",
    "\n",
    "# match column names by removing subscripts\n",
    "dfGG = dfGG.rename(columns=lambda x: x.replace('_GG','').replace('GG',''))\n",
    "dfMG = dfMG.rename(columns=lambda x: x.replace('_MG','').replace('MG',''))\n",
    "\n",
    "# change some column names to match the discovery/test data sets\n",
    "renameDict = {'LocIndexL':'AnatDev01',\n",
    "              'LocAnat':'AnatDev02',\n",
    "              'Division':'AnatDev03',\n",
    "              'DivisionLat':'AnatDev04',\n",
    "              'LesionSize':'MajorLengthIndex',\n",
    "              'SmoothCapsularBulgin':'SmoothCapsularBulging',\n",
    "              'UnsharpMargins':'UnsharpMargin',\n",
    "              'irregularContour':'IrregularContour',\n",
    "              'BlackEstrition':'BlackEstritionPeripFat',\n",
    "              'measurableECE':'MeasurableECE',\n",
    "              'retroprostaticAngleObl':'RetroprostaticAngleOblit'}\n",
    "dfGG.rename(renameDict, axis=1, inplace=True)\n",
    "dfMG.rename(renameDict, axis=1, inplace=True)\n",
    "\n",
    "# highsignalT1FS is missing from this spreadsheet, so fill in with default value.\n",
    "# Fortunately, this feature is not selected in the final model, but we need it there for compatibility.\n",
    "dfGG.loc[:, 'highsignalT1FS'] = 0\n",
    "dfMG.loc[:, 'highsignalT1FS'] = 0\n",
    "\n",
    "iccDict = {}\n",
    "for col in dfGG.drop(['PID', 'highsignalT1FS'], axis=1):\n",
    "    data = np.stack((dfGG[col], dfMG[col]), axis=1)\n",
    "    iccDict['semantic_' + col] = intraclass_correlation(data, \"twoway\", \"agreement\").value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and prepare radiomics data (discovery and test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "radiomicsFile = os.path.join(dataFolder, 'ECE_Semantic_Data', 'radiomicFeatures__202209271126.csv')\n",
    "\n",
    "dfRad = pd.read_csv(radiomicsFile)\n",
    "dfRad.drop(list(dfRad.filter(regex = 'source')), axis = 1, inplace = True)\n",
    "dfRad.drop(list(dfRad.filter(regex = 'diagnostics')), axis = 1, inplace = True)\n",
    "dfRad.drop(list(dfRad.filter(regex = 'histogram')), axis = 1, inplace = True)\n",
    "\n",
    "# remove feature sets we don't want to use and remove string from the one that is left\n",
    "dfRad.drop(list(dfRad.filter(regex = 'noNormalize|maskNormalize')), axis = 1, inplace = True)\n",
    "dfRad = dfRad.rename(columns=lambda x: x.replace('normalized_',''))\n",
    "\n",
    "# To match the semantic data file\n",
    "dfRad['StudyPatientName'] = dfRad['StudyPatientName'].str.replace('_',' ')\n",
    "\n",
    "# sensible prefix \n",
    "dfRad = dfRad.rename(columns=lambda x: x.replace('original','radiomics'))\n",
    "\n",
    "# split off the repro rows\n",
    "dfRep1 = dfRad.loc[dfRad.StudyPatientName.str.contains('rep'),:].copy()\n",
    "dfRep1['StudyPatientName'] = dfRep1['StudyPatientName'].str.replace(' repro','')\n",
    "dfRep1.sort_values('StudyPatientName', axis=0, inplace=True)\n",
    "dfRep1.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# remove repro from main data frame\n",
    "dfRad = dfRad.loc[~dfRad.StudyPatientName.str.contains('rep'),:]\n",
    "dfRad.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# main data rows for same patients as repro\n",
    "dfRep0 = dfRad.loc[dfRad['StudyPatientName'].isin(dfRep1['StudyPatientName'])].copy()\n",
    "dfRep0.sort_values('StudyPatientName', axis=0, inplace=True)\n",
    "dfRep0.reset_index(inplace=True, drop=True)\n",
    "\n",
    "for col in dfRep1.drop('StudyPatientName', axis=1):\n",
    "    data = np.stack((dfRep0[col], dfRep1[col]), axis=1)\n",
    "    iccDict[col] = intraclass_correlation(data, \"twoway\", \"agreement\").value\n",
    "\n",
    "# dfRad = dfRad.filter(regex='shape|firstorder|StudyPatientName')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and prepare semantic data (discovery and test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "discoveryFile = os.path.join(dataFolder, 'ECE_Semantic_Data', 'discovery.csv')\n",
    "externalTestFile = os.path.join(dataFolder, 'ECE_Semantic_Data', 'external.csv')\n",
    "    \n",
    "# load data\n",
    "dfTrain = pd.read_csv(discoveryFile)\n",
    "dfTest  = pd.read_csv(externalTestFile)\n",
    "\n",
    "# drop features we are not going to use for classification\n",
    "dfTrain.drop(['Gleason biopsy','TumorGradeMRI'], inplace=True, axis=1)\n",
    "dfTest.drop(['Gleason biopsy','TumorGradeMRI'], inplace=True, axis=1)\n",
    "\n",
    "# change this feature to have a more descriptive name\n",
    "dfTrain.insert(1, 'Gleason>(3+4)', dfTrain['GleasonBinary'])\n",
    "dfTest.insert(1, 'Gleason>(3+4)', dfTest['GleasonBinary'])\n",
    "dfTrain.drop('GleasonBinary', axis=1, inplace=True)\n",
    "dfTest.drop('GleasonBinary', axis=1, inplace=True)\n",
    "\n",
    "# make these features binary 0/1\n",
    "toBinary = ['SmoothCapsularBulging' ,'CapsularDisruption', 'UnsharpMargin', 'IrregularContour', 'BlackEstritionPeripFat', 'MeasurableECE', 'RetroprostaticAngleOblit', 'highsignalT1FS']\n",
    "for tb in toBinary:\n",
    "    dfTrain[tb]  = dfTrain[tb].map(dict(YES=1, NO=0))\n",
    "    dfTest[tb] = dfTest[tb].map(dict(YES=1, NO=0))\n",
    "\n",
    "# simplify PIRADS (as ECE rate for 3 and 4 is around 20% and for 5 is around 75%)\n",
    "dfTrain.insert(4, 'PIRADS>4', (dfTrain['IndLesPIRADS_V2'] > 4).astype(int))\n",
    "dfTrain.drop('IndLesPIRADS_V2', axis=1, inplace=True)\n",
    "dfTest.insert(4, 'PIRADS>4', (dfTest['IndLesPIRADS_V2'] > 4).astype(int))\n",
    "dfTest.drop('IndLesPIRADS_V2', axis=1, inplace=True)\n",
    "\n",
    "# log transform some features to get rid of long tail\n",
    "dfTrain.ProstateVolume = np.log(dfTrain.ProstateVolume)\n",
    "dfTest.ProstateVolume = np.log(dfTest.ProstateVolume)\n",
    "dfTrain.PSA = np.log(dfTrain.PSA)\n",
    "dfTest.PSA = np.log(dfTest.PSA)\n",
    "\n",
    "# is missing in test and training, so replace both with median from the training data\n",
    "psaTrainMedian = np.nanmedian(np.array(dfTrain.PSA))\n",
    "dfTrain.PSA.fillna(psaTrainMedian, inplace=True)\n",
    "dfTest.PSA.fillna(psaTrainMedian, inplace=True)\n",
    "\n",
    "# this feature is not selected in the semantic model, so this has no effect\n",
    "# fill in with the most common value\n",
    "dfTest.highsignalT1FS.fillna(0, inplace=True)\n",
    "\n",
    "# add string to names for easy manipulation of groups\n",
    "clinicalFeatures = ['Gleason>(3+4)', 'ProstateVolume', 'PSA', 'PIRADS>4']\n",
    "semanticFeatures = list(set(dfTrain.columns) - set(clinicalFeatures) - set(['PID', 'ECE_Pathology']))\n",
    "dfTrain = dfTrain.rename(columns=lambda x: 'clinical_' + x if x in clinicalFeatures else x)\n",
    "dfTest = dfTest.rename(columns=lambda x: 'clinical_' + x if x in clinicalFeatures else x)\n",
    "dfTrain = dfTrain.rename(columns=lambda x: 'semantic_' + x if x in semanticFeatures else x)\n",
    "dfTest = dfTest.rename(columns=lambda x: 'semantic_' + x if x in semanticFeatures else x)\n",
    "\n",
    "# merge radiomics \n",
    "dfTrain = dfTrain.merge(dfRad, left_on='PID', right_on='StudyPatientName')\n",
    "dfTest = dfTest.merge(dfRad, left_on='PID', right_on='StudyPatientName')\n",
    "dfTrain = dfTrain.drop(['PID', 'StudyPatientName'], axis=1)\n",
    "dfTest = dfTest.drop(['PID', 'StudyPatientName'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main model fitting function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# some functions to help get smooth ROC and DCA curves for the test data\n",
    "\n",
    "def jitterColumns(df, scale):\n",
    "    for col in df:\n",
    "        df[col] = df[col] + np.random.normal(loc=0, scale=scale*np.std(df[col]), size=df[col].shape)\n",
    "    return df\n",
    "\n",
    "def replicateDf(df, N):\n",
    "    dfOut = df.copy()\n",
    "    for n in range(N-1):\n",
    "        dfOut = pd.concat([dfOut, df], axis=0)\n",
    "    return dfOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def fitModel(dfTrain, dfTest, pipeline, coefDisplayFunction=None, keepRegex=None, permutationTest=False, jitterTestData=False):\n",
    "\n",
    "    # reproducible execution\n",
    "    seed = 42\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # get training and test data\n",
    "    XTrain = dfTrain.drop('ECE_Pathology', axis=1)\n",
    "    XTest = dfTest.drop('ECE_Pathology', axis=1)\n",
    "    yTrain = dfTrain.ECE_Pathology\n",
    "    yTest = dfTest.ECE_Pathology\n",
    "    \n",
    "    # keep features as indicated\n",
    "    if keepRegex is not None:\n",
    "        XTrain = XTrain.filter(regex = keepRegex)\n",
    "        XTest = XTest.filter(regex = keepRegex)\n",
    "\n",
    "    # make sure correlationSelector will not remove any clinical or semantic features\n",
    "    if pipeline.steps[0][0] == 'correlationSelector':\n",
    "        pipeline.steps[0][1].namedColumnsKeep = [x for x in XTrain.columns if 'clinical' in x or 'semantic' in x]\n",
    "        \n",
    "    # drop low variance radiomics features (in practice this only includes radiomics_glcm_Idmn)\n",
    "    CoV = pd.DataFrame(XTrain.apply(lambda x: np.std(x)/np.mean(x), axis=0))\n",
    "    lowVarianceFeatures = CoV.loc[np.abs(CoV.loc[:,0])<0.01,:].index.values.tolist()\n",
    "    lowVarianceFeatures = [x for x in lowVarianceFeatures if 'clinical' not in x and 'semantic' not in x]\n",
    "    XTrain.drop(lowVarianceFeatures, axis = 1, inplace = True)\n",
    "    XTest.drop(lowVarianceFeatures, axis = 1, inplace = True)\n",
    "\n",
    "    # fit to all data\n",
    "    pipeline.fit(XTrain, yTrain)\n",
    "\n",
    "    # cross-validate\n",
    "    outer_cv = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats)\n",
    "    cv_result = cross_validate(pipeline, \n",
    "                               XTrain, \n",
    "                               yTrain, \n",
    "                               cv=outer_cv, \n",
    "                               scoring=scorers,\n",
    "                               return_estimator=True, \n",
    "                               verbose=0, \n",
    "                               n_jobs=-1)\n",
    "\n",
    "    # print CV scores\n",
    "    AUC_CV = np.mean(cv_result['test_roc_auc'])\n",
    "    Accuracy_CV = np.mean(cv_result['test_accuracy'])\n",
    "    F1_CV = np.mean(cv_result['test_f1'])\n",
    "    print('AUCROC   (CV) = ' + str(AUC_CV.round(3)) + ' \\u00B1 ' + str(np.round(np.std(cv_result['test_roc_auc']),3)))\n",
    "    print('Accuracy (CV) = ' + str(Accuracy_CV.round(3)) + ' \\u00B1 ' + str(np.round(np.std(cv_result['test_accuracy']),3)))\n",
    "    print('F1       (CV) = ' + str(F1_CV.round(3)) + ' \\u00B1 ' + str(np.round(np.std(cv_result['test_f1']),3)))\n",
    "\n",
    "    FNR, FPR, DCA = unpack_scorers(cv_result)\n",
    "\n",
    "    # permutation testing\n",
    "    if permutationTest:\n",
    "        outer_cv.n_repeats = 1\n",
    "\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "        #\n",
    "        scoreDirect, perm_scores, pValueDirect = permutation_test_score(pipeline, \n",
    "                                                                        XTrain, \n",
    "                                                                        yTrain, \n",
    "                                                                        scoring=\"roc_auc\",\n",
    "                                                                        cv=outer_cv, \n",
    "                                                                        n_permutations=n_permutations,\n",
    "                                                                        verbose=0, n_jobs=-1)\n",
    "        #\n",
    "        warnings.simplefilter('default')\n",
    "        os.environ[\"PYTHONWARNINGS\"] = 'default'\n",
    "\n",
    "        # pValueDirect is computed using scoreDirect and assumes only one outer CV run\n",
    "        # We have used repeated outer CV, so the following code correctly computes the p-value of our repeated CV performance estimate\n",
    "        # Actually, it doesn't seem to make much difference, so am relaxed about that.\n",
    "\n",
    "        p_values = []\n",
    "        scores_roc_auc = np.mean(np.reshape(cv_result['test_roc_auc'], (n_repeats, -1)), axis=1)\n",
    "        for score in scores_roc_auc:\n",
    "            p_values.append((np.count_nonzero(perm_scores >= score) + 1) / (n_permutations + 1))\n",
    "        pValue_CV = np.mean(p_values)\n",
    "        print('p-value       = ' + str(pValue_CV.round(4)))\n",
    "    else:\n",
    "        pValue_CV = None\n",
    "    \n",
    "    # replicate and add jitter to test data to give smoother roc and DCA curves\n",
    "    if jitterTestData:\n",
    "        XTest = replicateDf(XTest, 20)\n",
    "        yTest = replicateDf(yTest, 20)\n",
    "        XTest = jitterColumns(XTest, 0.1)\n",
    "\n",
    "    # get scores and predicted class info\n",
    "    test_score = pipeline.predict_proba(XTest)[:, 1]\n",
    "    test_class = pipeline.predict(XTest)\n",
    "\n",
    "    # test scores from main model\n",
    "    testAUROC = roc_auc_score(yTest, test_score)\n",
    "    testAccuracy = accuracy_score(yTest, test_class)\n",
    "    testF1 = f1_score(yTest, test_class)\n",
    "\n",
    "    pValueTest = mannwhitneyu(test_score[yTest==0], test_score[yTest==1], alternative='two-sided').pvalue\n",
    "\n",
    "    # print the test performance metrics\n",
    "    print('\\nAUCROC   (test) = ' + str(np.round(testAUROC,3)))\n",
    "    print('Accuracy (test) = ' + str(np.round(testAccuracy,3)))\n",
    "    print('F1       (test) = ' + str(np.round(testF1,3)))\n",
    "    print('p-value  (test) = ' + str(np.round(pValueTest, 6)))\n",
    "\n",
    "    if coefDisplayFunction is not None:\n",
    "        dfCoefResults = coefDisplayFunction(pipeline, XTrain.columns, cv_result)\n",
    "\n",
    "    out = {'test_AUC':testAUROC,\n",
    "           'test_score':test_score,\n",
    "           'test_class':test_class,\n",
    "           'test_accuracy':testAccuracy,\n",
    "           'test_f1':testF1,\n",
    "           'test_pValue':pValueTest,\n",
    "           'AUC_CV':AUC_CV,\n",
    "           'Accuracy_CV':Accuracy_CV,\n",
    "           'F1_CV':F1_CV,\n",
    "           'pValue_CV':pValue_CV,\n",
    "           'FNR_CV':FNR,\n",
    "           'FPR_CV':FPR,\n",
    "           'DCA_CV':DCA,\n",
    "           'XTrain':XTrain.copy(),\n",
    "           'XTest':XTest.copy(),\n",
    "           'yTrain':yTrain.copy(),\n",
    "           'yTest':yTest.copy(),\n",
    "           'pipeline':pipeline\n",
    "          }\n",
    "    \n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three logistic regression pipelines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# basic logistic regression, no regularisation\n",
    "pipelineLRsimple = Pipeline(steps=[('scaler', StandardScaler()),\n",
    "                                   ('lr', LogisticRegression(penalty='none'))])\n",
    "\n",
    "# logistic regression with lasso\n",
    "pipelineLRlasso = Pipeline(steps=[('scaler', StandardScaler()), \n",
    "                                  ('lr', LogisticRegressionCV(Cs=20, \n",
    "                                                              cv=10, \n",
    "                                                              solver=\"liblinear\",\n",
    "                                                              max_iter=10000, \n",
    "                                                              penalty='l1',\n",
    "                                                              random_state=42))])\n",
    "\n",
    "# logistic regression with lasso, preceded by correlation feature reduction\n",
    "# fitModel function will modify pipeline to make sure the clinical and semantic features are not affected by\n",
    "# correlation feature reduction\n",
    "pipelineCfrLRlasso = Pipeline([('correlationSelector', featSelCorr(threshold=0.9,\n",
    "                                                                   exact=False,\n",
    "                                                                   featureGroupHierarchy=['shape_MeshVolume',\n",
    "                                                                                          'shape',\n",
    "                                                                                          'firstorder'])),\n",
    "                               ('scaler', StandardScaler()),\n",
    "                               ('lr', GridSearchCV(estimator=LogisticRegression(solver=\"liblinear\", \n",
    "                                                                                max_iter=10000, \n",
    "                                                                                penalty='l1'), \n",
    "                                                   param_grid={'C':np.logspace(np.log10(0.05), np.log10(50), 20)}, \n",
    "                                                   cv=StratifiedKFold(n_splits=10), \n",
    "                                                   refit=True, \n",
    "                                                   verbose=0, \n",
    "                                                   scoring='neg_log_loss', \n",
    "                                                   n_jobs=1))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to display non-zero logistic regression coeffients for the pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def coefDispFunLRsimple(pipeline, featureNames, dummy):\n",
    "    dfCoefResults = pd.DataFrame({'Feature':[x.replace('clinical_','') for x in featureNames], \n",
    "                                  'Coeff':np.squeeze(pipeline._final_estimator.coef_)})\n",
    "    dfCoefResults.sort_values(by='Coeff', key=abs, inplace=True, ascending=False)\n",
    "    display(dfCoefResults.style.hide_index())\n",
    "    print(dfCoefResults.to_string(index=False))\n",
    "\n",
    "def coefDispFunLRlasso(pipeline, featureNames, cv_result):\n",
    "\n",
    "    # get frequency that features are non-zero across the repeated cv splits\n",
    "    coef_cv = np.zeros((len(cv_result['estimator']), len(featureNames)))\n",
    "    for n, res in enumerate(cv_result['estimator']):\n",
    "        coef_cv[n, :] = res._final_estimator.coef_\n",
    "    coef_freq = np.sum(coef_cv != 0, axis=0) / (n_repeats * n_splits)\n",
    "\n",
    "    # put icc values in array for including in DataFrame\n",
    "    iccList = []\n",
    "    for feat in featureNames:\n",
    "        if feat in iccDict:\n",
    "            iccList.append(iccDict[feat])\n",
    "        else:\n",
    "            iccList.append('-')\n",
    "\n",
    "    # simplify feature names\n",
    "    featureNames = [x.replace('clinical_','') for x in featureNames]\n",
    "    featureNames = [x.replace('semantic_','') for x in featureNames]\n",
    "    featureNames = [x.replace('radiomics_','') for x in featureNames]\n",
    "            \n",
    "    # display sorted coefficients and selection frequency\n",
    "    coeffs = np.squeeze(pipeline._final_estimator.coef_)\n",
    "    dfCoefResults = pd.DataFrame({'Feature': featureNames, 'Coeff': coeffs, 'Freq': coef_freq, 'ICC':iccList})\n",
    "    dfCoefResults.sort_values(by=['Coeff', 'Freq'], key=abs, inplace=True, ascending=False)\n",
    "    display(dfCoefResults.loc[dfCoefResults.Coeff != 0, :].style.hide_index())\n",
    "    print(dfCoefResults.loc[dfCoefResults.Coeff != 0, :].to_string(index=False))\n",
    "\n",
    "def coefDispFunCfrLRlasso(pipeline, featureNames, cv_result):\n",
    "    \n",
    "    # get frequency that features are non-zero across the repeated cv splits\n",
    "    coef_cv = np.zeros((len(cv_result['estimator']), len(featureNames)))\n",
    "    fs_mask = np.zeros((len(cv_result['estimator']), len(featureNames)))\n",
    "    for n, res in enumerate(cv_result['estimator']):\n",
    "        fs_mask[n, :] = res.steps[0][1].mask_\n",
    "        coef_cv[n, res.steps[0][1].mask_] = res._final_estimator.best_estimator_.coef_\n",
    "    coef_freq = np.sum(coef_cv != 0, axis=0) / (n_repeats * n_splits)\n",
    "\n",
    "    # put icc values in array for including in DataFrame\n",
    "    iccList = []\n",
    "    for feat in featureNames:\n",
    "        if feat in iccDict:\n",
    "            iccList.append(iccDict[feat])\n",
    "        else:\n",
    "            iccList.append('-')\n",
    "\n",
    "    # simplify feature names\n",
    "    featureNames = [x.replace('clinical_','') for x in featureNames]\n",
    "    featureNames = [x.replace('semantic_','') for x in featureNames]\n",
    "    featureNames = [x.replace('radiomics_','') for x in featureNames]\n",
    "            \n",
    "    # display sorted coefficients and selection frequency\n",
    "    coeffs = np.zeros(len(featureNames))\n",
    "    coeffs[pipeline.steps[0][1].mask_] = np.squeeze(pipeline._final_estimator.best_estimator_.coef_)\n",
    "\n",
    "    dfCoefResults = pd.DataFrame({'Feature': featureNames, 'Coeff': coeffs, 'Freq': coef_freq, 'ICC':iccList})\n",
    "    dfCoefResults.sort_values(by=['Coeff', 'Freq'], key=abs, inplace=True, ascending=False)\n",
    "    display(dfCoefResults.loc[dfCoefResults.Coeff != 0, :].style.hide_index())\n",
    "    print(dfCoefResults.loc[dfCoefResults.Coeff != 0, :].to_string(index=False))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for SHAP beeswarm plots for the pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def showShapLR(r, file=None):\n",
    "    standardiser = r['pipeline'].steps[0][1]\n",
    "\n",
    "    X = pd.DataFrame(columns=r['XTrain'].columns, data=standardiser.transform(r['XTrain'].copy()))\n",
    "    X = X.rename(columns=lambda x: x.replace('clinical_',''))\n",
    "    X = X.rename(columns=lambda x: x.replace('semantic_',''))\n",
    "    X = X.rename(columns=lambda x: x.replace('radiomics_',''))\n",
    "        \n",
    "    explainer = shap.explainers.Linear(r['pipeline']._final_estimator, X)\n",
    "    shap_values = explainer(X)\n",
    "    max_display = 1 + np.sum(r['pipeline']._final_estimator.coef_ != 0)\n",
    "    shap.plots.beeswarm(shap_values, max_display=max_display, show=False)\n",
    "\n",
    "    if file is not None:\n",
    "        plt.savefig(file, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "def showShapLRcfr(r, file=None):\n",
    "\n",
    "    mask = r['pipeline'].steps[0][1].mask_\n",
    "    standardiser = r['pipeline'].steps[1][1]\n",
    "\n",
    "    X = r['XTrain'].loc[:,mask]\n",
    "    X = standardiser.transform(X)\n",
    "    X = pd.DataFrame(columns=r['XTrain'].columns[mask], data=X)\n",
    "    X = X.rename(columns=lambda x: x.replace('clinical_',''))\n",
    "    X = X.rename(columns=lambda x: x.replace('semantic_',''))\n",
    "    X = X.rename(columns=lambda x: x.replace('radiomics_',''))\n",
    "    \n",
    "    model = r['pipeline']._final_estimator.best_estimator_\n",
    "    explainer = shap.explainers.Linear(model, X)\n",
    "    shap_values = explainer(X)\n",
    "    max_display = 1 + np.sum(model.coef_ != 0)\n",
    "    shap.plots.beeswarm(shap_values, max_display=max_display, show=False)\n",
    "\n",
    "    if file is not None:\n",
    "        plt.savefig(file, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit models to four combinations of input features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clinical features\n",
      "\n",
      "AUCROC   (CV) = 0.829 ± 0.142\n",
      "Accuracy (CV) = 0.798 ± 0.104\n",
      "F1       (CV) = 0.564 ± 0.255\n",
      "\n",
      "AUCROC   (test) = 0.773\n",
      "Accuracy (test) = 0.746\n",
      "F1       (test) = 0.61\n",
      "p-value  (test) = 0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_898e3552_3f7d_11ed_b57c_784f437c194a\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Feature</th>        <th class=\"col_heading level0 col1\" >Coeff</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_898e3552_3f7d_11ed_b57c_784f437c194arow0_col0\" class=\"data row0 col0\" >Gleason>(3+4)</td>\n",
       "                        <td id=\"T_898e3552_3f7d_11ed_b57c_784f437c194arow0_col1\" class=\"data row0 col1\" >1.230</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_898e3552_3f7d_11ed_b57c_784f437c194arow1_col0\" class=\"data row1 col0\" >ProstateVolume</td>\n",
       "                        <td id=\"T_898e3552_3f7d_11ed_b57c_784f437c194arow1_col1\" class=\"data row1 col1\" >-0.540</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_898e3552_3f7d_11ed_b57c_784f437c194arow2_col0\" class=\"data row2 col0\" >PIRADS>4</td>\n",
       "                        <td id=\"T_898e3552_3f7d_11ed_b57c_784f437c194arow2_col1\" class=\"data row2 col1\" >0.347</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_898e3552_3f7d_11ed_b57c_784f437c194arow3_col0\" class=\"data row3 col0\" >PSA</td>\n",
       "                        <td id=\"T_898e3552_3f7d_11ed_b57c_784f437c194arow3_col1\" class=\"data row3 col1\" >0.086</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fca780c74a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Feature  Coeff\n",
      "  Gleason>(3+4)  1.230\n",
      " ProstateVolume -0.540\n",
      "       PIRADS>4  0.347\n",
      "            PSA  0.086\n",
      "\n",
      "\n",
      "\n",
      "Clinical + Semantic features\n",
      "\n",
      "AUCROC   (CV) = 0.843 ± 0.133\n",
      "Accuracy (CV) = 0.853 ± 0.077\n",
      "F1       (CV) = 0.632 ± 0.208\n",
      "\n",
      "AUCROC   (test) = 0.894\n",
      "Accuracy (test) = 0.746\n",
      "F1       (test) = 0.464\n",
      "p-value  (test) = 0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_8fb1f964_3f7d_11ed_a883_784f437c194a\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Feature</th>        <th class=\"col_heading level0 col1\" >Coeff</th>        <th class=\"col_heading level0 col2\" >Freq</th>        <th class=\"col_heading level0 col3\" >ICC</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_8fb1f964_3f7d_11ed_a883_784f437c194arow0_col0\" class=\"data row0 col0\" >MeasurableECE</td>\n",
       "                        <td id=\"T_8fb1f964_3f7d_11ed_a883_784f437c194arow0_col1\" class=\"data row0 col1\" >0.662</td>\n",
       "                        <td id=\"T_8fb1f964_3f7d_11ed_a883_784f437c194arow0_col2\" class=\"data row0 col2\" >1.000</td>\n",
       "                        <td id=\"T_8fb1f964_3f7d_11ed_a883_784f437c194arow0_col3\" class=\"data row0 col3\" >0.787</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_8fb1f964_3f7d_11ed_a883_784f437c194arow1_col0\" class=\"data row1 col0\" >Gleason>(3+4)</td>\n",
       "                        <td id=\"T_8fb1f964_3f7d_11ed_a883_784f437c194arow1_col1\" class=\"data row1 col1\" >0.297</td>\n",
       "                        <td id=\"T_8fb1f964_3f7d_11ed_a883_784f437c194arow1_col2\" class=\"data row1 col2\" >0.790</td>\n",
       "                        <td id=\"T_8fb1f964_3f7d_11ed_a883_784f437c194arow1_col3\" class=\"data row1 col3\" >-</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_8fb1f964_3f7d_11ed_a883_784f437c194arow2_col0\" class=\"data row2 col0\" >IrregularContour</td>\n",
       "                        <td id=\"T_8fb1f964_3f7d_11ed_a883_784f437c194arow2_col1\" class=\"data row2 col1\" >0.213</td>\n",
       "                        <td id=\"T_8fb1f964_3f7d_11ed_a883_784f437c194arow2_col2\" class=\"data row2 col2\" >0.790</td>\n",
       "                        <td id=\"T_8fb1f964_3f7d_11ed_a883_784f437c194arow2_col3\" class=\"data row2 col3\" >0.417</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_8fb1f964_3f7d_11ed_a883_784f437c194arow3_col0\" class=\"data row3 col0\" >CapsularDisruption</td>\n",
       "                        <td id=\"T_8fb1f964_3f7d_11ed_a883_784f437c194arow3_col1\" class=\"data row3 col1\" >0.098</td>\n",
       "                        <td id=\"T_8fb1f964_3f7d_11ed_a883_784f437c194arow3_col2\" class=\"data row3 col2\" >0.750</td>\n",
       "                        <td id=\"T_8fb1f964_3f7d_11ed_a883_784f437c194arow3_col3\" class=\"data row3 col3\" >0.352</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fca780c76d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Feature  Coeff  Freq    ICC\n",
      "      MeasurableECE  0.662  1.00  0.787\n",
      "      Gleason>(3+4)  0.297  0.79      -\n",
      "   IrregularContour  0.213  0.79  0.417\n",
      " CapsularDisruption  0.098  0.75  0.352\n",
      "\n",
      "\n",
      "\n",
      "Clinical + Radiomic features\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-808a4547a505>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m                \u001b[0mkeepRegex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'clinical|radiomic'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                \u001b[0mpermutationTest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpermutationTest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                jitterTestData=jitterTestData)\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0mrcr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Clinical + Radiomic'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mjitterTestData\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-9b36321e45cc>\u001b[0m in \u001b[0;36mfitModel\u001b[0;34m(dfTrain, dfTest, pipeline, coefDisplayFunction, keepRegex, permutationTest, jitterTestData)\u001b[0m\n\u001b[1;32m     39\u001b[0m                                \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                                \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                                n_jobs=-1)\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# print CV scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 248\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "jitterTestData = False\n",
    "\n",
    "# for figure naming\n",
    "if jitterTestData:\n",
    "    jitterStr = '_testJitter'\n",
    "else:\n",
    "    jitterStr = ''\n",
    "    \n",
    "print('Clinical features\\n')\n",
    "rc = fitModel(dfTrain,\n",
    "              dfTest,\n",
    "              pipelineLRsimple, \n",
    "              coefDisplayFunction=coefDispFunLRsimple, \n",
    "              keepRegex='clinical', \n",
    "              permutationTest=permutationTest,\n",
    "              jitterTestData=jitterTestData)\n",
    "rc['label'] = 'Clinical'\n",
    "if not jitterTestData:\n",
    "    showShapLR(rc, file=os.path.join(dataFolder, 'figures', 'shap_clinical.pdf'))\n",
    "\n",
    "\n",
    "print('\\n\\n\\nClinical + Semantic features\\n')\n",
    "rcs = fitModel(dfTrain,\n",
    "               dfTest,\n",
    "               pipelineLRlasso, \n",
    "               coefDisplayFunction=coefDispFunLRlasso, \n",
    "               keepRegex='clinical|semantic', \n",
    "               permutationTest=permutationTest,\n",
    "               jitterTestData=jitterTestData)\n",
    "rcs['label'] = 'Clinical + Semantic'\n",
    "if not jitterTestData:\n",
    "    showShapLR(rcs, file=os.path.join(dataFolder, 'figures', 'shap_clinical_semantic.pdf'))\n",
    "\n",
    "\n",
    "print('\\n\\n\\nClinical + Radiomic features\\n')\n",
    "rcr = fitModel(dfTrain,\n",
    "               dfTest,\n",
    "               pipelineCfrLRlasso, \n",
    "               coefDisplayFunction=coefDispFunCfrLRlasso, \n",
    "               keepRegex='clinical|radiomic', \n",
    "               permutationTest=permutationTest,\n",
    "               jitterTestData=jitterTestData)\n",
    "rcr['label'] = 'Clinical + Radiomic'\n",
    "if not jitterTestData:\n",
    "    showShapLRcfr(rcr, file=os.path.join(dataFolder, 'figures', 'shap_clinical_radiomic.pdf'))\n",
    "\n",
    "\n",
    "print('\\n\\n\\nClinical + Semantic + Radiomic features\\n')\n",
    "rcsr = fitModel(dfTrain,\n",
    "                dfTest,\n",
    "                pipelineCfrLRlasso, \n",
    "                coefDisplayFunction=coefDispFunCfrLRlasso, \n",
    "                keepRegex='clinical|semantic|radiomic', \n",
    "                permutationTest=permutationTest,\n",
    "                jitterTestData=jitterTestData)\n",
    "rcsr['label'] = 'Clinical + Semantic + Radiomic'\n",
    "if not jitterTestData:\n",
    "    showShapLRcfr(rcsr, file=os.path.join(dataFolder, 'figures', 'shap_clinical_semantic_radiomic.pdf'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make some plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(12,12))\n",
    "ax = ax.ravel()\n",
    "\n",
    "# discovery data plots\n",
    "\n",
    "models = [rc, rcs, rcr, rcsr]\n",
    "\n",
    "# ROC\n",
    "for r in models:\n",
    "    ax[0].plot(r['FPR_CV']['values'], \n",
    "               [1-x for x in r['FNR_CV']['values']], \n",
    "               label = 'AUC = ' + str(np.round(r['AUC_CV'],3)) + ' ' + r['label'])\n",
    "ax[0].set_xlabel('1 - Specificity', fontsize=14)\n",
    "ax[0].set_ylabel('Sensitivity', fontsize=14)\n",
    "ax[0].set_title('ROC', fontsize=16, fontweight='bold')\n",
    "ax[0].legend(fontsize=9)\n",
    "ax[0].text(-0.3, 0.5, 'Discovery data, cross-validated', fontsize=16, fontweight='bold', rotation=90, verticalalignment='center')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# DCA\n",
    "TPtrain = np.sum(dfTrain.ECE_Pathology==1)/dfTrain.shape[0]\n",
    "FPtrain = np.sum(dfTrain.ECE_Pathology==0)/dfTrain.shape[0]\n",
    "for r in models:\n",
    "    exactScale = TPtrain/r['DCA_CV']['values'][0]\n",
    "    ax[1].plot(r['DCA_CV']['thresholds'], [x*exactScale for x in r['DCA_CV']['values']], label=r['label'])\n",
    "# add treat all and treat none\n",
    "pt = np.array(rc['DCA_CV']['thresholds'])\n",
    "ax[1].plot(pt, (TPtrain - FPtrain*pt/(1-pt)), label='Treat all', color='k', linestyle='--')\n",
    "ax[1].plot([0, 1], [0, 0], label='Treat none', color='k', linestyle=':')\n",
    "\n",
    "ax[1].set_title('Net benefit curve', fontsize=16, fontweight='bold')\n",
    "ax[1].legend(fontsize=9)\n",
    "ax[1].set_xlabel('Threshold', fontsize=14)\n",
    "ax[1].set_ylabel('Net benefit curve', fontsize=14)\n",
    "ax[1].set_ylim([-0.2, 0.4])\n",
    "ax[1].set_xlim([0, 0.4])\n",
    "\n",
    "# test data plots\n",
    "\n",
    "# ROC\n",
    "for r in models:\n",
    "    fpr, tpr, _ = roc_curve(r['yTest'], r['test_score'])\n",
    "    ax[2].plot(fpr, tpr, label='AUC = ' + str(np.round(r['test_AUC'],3)) + ' ' + r['label'])\n",
    "ax[2].set_xlabel('1 - Specificity', fontsize=14)\n",
    "ax[2].set_ylabel('Sensitivity', fontsize=14)\n",
    "ax[2].legend(fontsize=9)\n",
    "ax[2].text(-0.3, 0.5, 'Test data', fontsize=16, fontweight='bold', rotation=90, verticalalignment='center')\n",
    "\n",
    "# FNR, FPR and DCA\n",
    "for r in models:\n",
    "    thresh = np.unique(r['test_score'])\n",
    "    thresh = np.append(thresh, 1e-6)\n",
    "    thresh = np.append(thresh, 1-1e-6)\n",
    "    thresh = np.sort(thresh)\n",
    "    tn, fp, fn, tp = confusion_matrix_thresholds(r['yTest'], r['test_score'], thresh)\n",
    "    ax[3].plot(thresh, (tp - fp * (thresh / (1 - thresh))) / len(r['yTest']), label=r['label'])\n",
    "ax[3].plot(thresh, (tp[0] - fp[0] * (thresh / (1 - thresh))) / len(r['yTest']), label='Treat all', color='k', linestyle='--')\n",
    "ax[3].plot([0, 1], [0, 0], label='Treat none', color='k', linestyle=':')\n",
    "\n",
    "ax[3].legend(fontsize=9)\n",
    "ax[3].set_xlabel('Threshold', fontsize=14)\n",
    "ax[3].set_ylabel('Net benefit', fontsize=14)\n",
    "ax[3].set_ylim([-0.2, 0.4])\n",
    "ax[3].set_xlim([0, 0.4])\n",
    "\n",
    "\n",
    "figFile = os.path.join(dataFolder, 'figures', 'ROC_NetBenefit' + jitterStr + '.pdf')\n",
    "plt.savefig(figFile)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(12,12))\n",
    "ax = ax.ravel()\n",
    "\n",
    "# discovery data plots\n",
    "\n",
    "models = [rc, rcs, rcr, rcsr]\n",
    "\n",
    "# FNR\n",
    "for r in models:\n",
    "    ax[0].plot(r['FNR_CV']['thresholds'], r['FNR_CV']['values'], label=r['label'])\n",
    "ax[0].set_title('False negative rate', fontsize=16, fontweight='bold')\n",
    "ax[0].legend(fontsize=11)\n",
    "ax[0].set_xlabel('Threshold', fontsize=14)\n",
    "ax[0].set_ylabel('False negative rate', fontsize=14)\n",
    "ax[0].text(-0.3, 0.5, 'Discovery data, cross-validated', fontsize=16, fontweight='bold', rotation=90, verticalalignment='center')\n",
    "\n",
    "# FPR\n",
    "for r in models:\n",
    "    ax[1].plot(r['FPR_CV']['thresholds'], r['FPR_CV']['values'], label=r['label'])\n",
    "ax[1].set_title('False positive rate', fontsize=16, fontweight='bold')\n",
    "ax[1].legend(fontsize=11)\n",
    "ax[1].set_xlabel('Threshold', fontsize=14)\n",
    "ax[1].set_ylabel('False positive rate', fontsize=14)\n",
    "\n",
    "\n",
    "# test data plots\n",
    "\n",
    "# FNR, FPR and DCA\n",
    "for r in models:\n",
    "    thresh = np.unique(r['test_score'])\n",
    "    thresh = np.append(thresh, 1e-6)\n",
    "    thresh = np.append(thresh, 1-1e-6)\n",
    "    thresh = np.sort(thresh)\n",
    "    tn, fp, fn, tp = confusion_matrix_thresholds(r['yTest'], r['test_score'], thresh)\n",
    "    ax[2].plot(thresh, fn/(fn + tp), label=r['label'])\n",
    "    ax[3].plot(thresh, fp/(fp + tn), label=r['label'])\n",
    "\n",
    "ax[2].text(-0.3, 0.5, 'Test data', fontsize=16, fontweight='bold', rotation=90, verticalalignment='center')\n",
    "\n",
    "for axi in [2, 3]:\n",
    "    ax[axi].legend(fontsize=9)\n",
    "    ax[axi].set_xlabel('Threshold', fontsize=14)\n",
    "\n",
    "ax[2].set_ylabel('False negative rate', fontsize=14)\n",
    "ax[3].set_ylabel('False positive rate', fontsize=14)\n",
    "\n",
    "figFile = os.path.join(dataFolder, 'figures', 'FP_FN' + jitterStr + '.pdf')\n",
    "plt.savefig(figFile)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not jitterTestData:\n",
    "    pValue = 10**delong_roc_test(rc['yTest'], rcs['test_score'], rcsr['test_score'])[0,0]\n",
    "    print('Delong comparing clinical + semantic vs. clinical + semantic + radiomic\\np = ' + str(np.round(pValue,3)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
