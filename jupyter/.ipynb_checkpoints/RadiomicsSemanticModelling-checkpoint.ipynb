{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#pd.set_option('precision', 3)\n",
    "from itertools import compress\n",
    "import copy, sys, os, warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from pyirr import intraclass_correlation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold, RepeatedStratifiedKFold, permutation_test_score, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, roc_curve, confusion_matrix, make_scorer\n",
    "from scipy.stats import spearmanr, mannwhitneyu\n",
    "from compare_auc_delong import delong_roc_test\n",
    "import shap\n",
    "\n",
    "oldPath = os.path.join(os.path.expanduser('~'), 'Documents/GitHub/icrpythonradiomics/machineLearning')\n",
    "if os.path.exists(oldPath) and oldPath in sys.path:\n",
    "    sys.path.remove(oldPath)\n",
    "sys.path.append(os.path.join(os.path.expanduser('~'), 'Documents/git/git_icrpythonradiomics/machineLearning'))\n",
    "from featureSelection import featureSelection_correlation as featSelCorr\n",
    "\n",
    "dataFolder = os.path.join(os.path.expanduser('~'), 'Dropbox (ICR)/CLINMAG/Radiomics/ECE_Prostate_Semantic')\n",
    "\n",
    "# validation parameters\n",
    "n_splits = 10\n",
    "n_repeats = 10\n",
    "\n",
    "permutationTest = False\n",
    "n_permutations = 100\n",
    "\n",
    "crossValidate = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def confusion_matrix_thresholds(yTrue, yScore, thresholds):\n",
    "    tnArr, fpArr, fnArr, tpArr = [], [], [], []\n",
    "    nSamples = len(yTrue)\n",
    "    for thresh in thresholds:\n",
    "        tn, fp, fn, tp = confusion_matrix(yTrue, yScore>thresh).ravel()\n",
    "        tnArr.append(tn)\n",
    "        fpArr.append(fp)\n",
    "        fnArr.append(fn)\n",
    "        tpArr.append(tp)\n",
    "    return np.array(tnArr), np.array(fpArr), np.array(fnArr), np.array(tpArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calculate_fnr(y_true, y_pred, pt=0):\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred > pt).ravel()\n",
    "    return fn/(fn + tp)\n",
    "\n",
    "\n",
    "def calculate_fpr(y_true, y_pred, pt=0):\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred > pt).ravel()\n",
    "    return fp/(fp + tn)\n",
    "\n",
    "\n",
    "def calculate_net_benefit_score(y_true, y_pred, pt=0):\n",
    "    _, fp, _, tp = confusion_matrix(y_true, y_pred > pt).ravel()\n",
    "    net_benefit = (tp - fp * (pt / (1 - pt))) / len(y_true)\n",
    "    return net_benefit\n",
    "\n",
    "\n",
    "def unpack_scorers(cvr):\n",
    "\n",
    "    thresh_FNR, thresh_FPR, thresh_DCA, value_DCA, value_FNR, value_FPR = [], [], [], [], [], []\n",
    "    \n",
    "    for key, value in cvr.items():\n",
    "        if 'test_FNR' in key:\n",
    "            thresh_FNR.append(float(key.replace('test_FNR_','')))\n",
    "            value_FNR.append(np.mean(value))\n",
    "        if 'test_FPR' in key:\n",
    "            thresh_FPR.append(float(key.replace('test_FPR_','')))\n",
    "            value_FPR.append(np.mean(value))\n",
    "        if 'test_DCA' in key:\n",
    "            thresh_DCA.append(float(key.replace('test_DCA_','')))\n",
    "            value_DCA.append(np.mean(value))\n",
    "\n",
    "    idxFNR = np.argsort(thresh_FNR)\n",
    "    idxFPR = np.argsort(thresh_FPR)\n",
    "    idxDCA = np.argsort(thresh_DCA)\n",
    "\n",
    "    FNR = {'thresholds': [thresh_FNR[idx] for idx in idxFNR],\n",
    "           'values': [value_FNR[idx] for idx in idxFNR]}\n",
    "    \n",
    "    FPR = {'thresholds': [thresh_FPR[idx] for idx in idxFPR],\n",
    "           'values': [value_FPR[idx] for idx in idxFPR]}\n",
    "\n",
    "    DCA = {'thresholds': [thresh_DCA[idx] for idx in idxDCA],\n",
    "           'values': [value_DCA[idx] for idx in idxDCA]}\n",
    "    \n",
    "    return FNR, FPR, DCA\n",
    "\n",
    "# Make dictionary of scorers, each of which will compute one point on the FNR and FPR curves.\n",
    "# The dictionary key is used to keep track of the threshold value that was used.\n",
    "scorers = {}\n",
    "\n",
    "# Don't use 0 and 1 as endpoints as this causes numerical underflow.\n",
    "ptArr = np.round(np.linspace(0, 1, 101),2)\n",
    "ptArr[0] = np.round(0.0001,4)\n",
    "ptArr[-1] = np.round(0.9999,4)\n",
    "\n",
    "for pt in ptArr:\n",
    "    scorers['FNR_' + str(pt)] = make_scorer(calculate_fnr, pt = pt, needs_proba=True)\n",
    "    scorers['FPR_' + str(pt)] = make_scorer(calculate_fpr, pt = pt, needs_proba=True)\n",
    "    scorers['DCA_' + str(pt)] = make_scorer(calculate_net_benefit_score, pt = pt, needs_proba=True)\n",
    "\n",
    "# standard scorers    \n",
    "scorers['roc_auc'] = 'roc_auc'\n",
    "scorers['accuracy'] = 'accuracy'\n",
    "scorers['f1'] = 'f1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load two reader semantic data (for computing ICCs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "twoReaderFile = os.path.join(dataFolder, 'ECE_Semantic_Data', 'GG_MG.xlsx')\n",
    "\n",
    "# read spreadsheet\n",
    "df = pd.read_excel(twoReaderFile, sheet_name='GG_MG', engine='openpyxl')\n",
    "\n",
    "# remove features, as with the discovery/test data\n",
    "df.drop(['IndexLesion_GG', 'IndexLesionMG', 'GlobalStageGG', 'GlobalStageMG'], axis=1, inplace=True)\n",
    "\n",
    "# remove rows with missing data - need to check that this leaves the same patients for dfGG as in the discovery data set\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# split to each reader\n",
    "dfGG = df.filter(regex = 'GG|PID', axis = 1)\n",
    "dfMG = df.filter(regex='MG|PID', axis=1)\n",
    "\n",
    "# match column names by removing subscripts\n",
    "dfGG = dfGG.rename(columns=lambda x: x.replace('_GG','').replace('GG',''))\n",
    "dfMG = dfMG.rename(columns=lambda x: x.replace('_MG','').replace('MG',''))\n",
    "\n",
    "# change some column names to match the discovery/test data sets\n",
    "renameDict = {'LocIndexL':'AnatDev01',\n",
    "              'LocAnat':'AnatDev02',\n",
    "              'Division':'AnatDev03',\n",
    "              'DivisionLat':'AnatDev04',\n",
    "              'LesionSize':'MajorLengthIndex',\n",
    "              'SmoothCapsularBulgin':'SmoothCapsularBulging',\n",
    "              'UnsharpMargins':'UnsharpMargin',\n",
    "              'irregularContour':'IrregularContour',\n",
    "              'BlackEstrition':'BlackEstritionPeripFat',\n",
    "              'measurableECE':'MeasurableECE',\n",
    "              'retroprostaticAngleObl':'RetroprostaticAngleOblit'}\n",
    "dfGG.rename(renameDict, axis=1, inplace=True)\n",
    "dfMG.rename(renameDict, axis=1, inplace=True)\n",
    "\n",
    "# highsignalT1FS is missing from this spreadsheet, so fill in with default value.\n",
    "# Fortunately, this feature is not selected in the final model, but we need it there for compatibility.\n",
    "dfGG.loc[:, 'highsignalT1FS'] = 0\n",
    "dfMG.loc[:, 'highsignalT1FS'] = 0\n",
    "\n",
    "iccDict = {}\n",
    "for col in dfGG.drop(['PID', 'highsignalT1FS'], axis=1):\n",
    "    data = np.stack((dfGG[col], dfMG[col]), axis=1)\n",
    "    iccDict['semantic_' + col] = intraclass_correlation(data, \"twoway\", \"agreement\").value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and prepare radiomics data (discovery and test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "radiomicsFile = os.path.join(dataFolder, 'ECE_Semantic_Data', 'radiomicFeatures__202209271126.csv')\n",
    "\n",
    "dfRad = pd.read_csv(radiomicsFile)\n",
    "dfRad.drop(list(dfRad.filter(regex = 'source')), axis = 1, inplace = True)\n",
    "dfRad.drop(list(dfRad.filter(regex = 'diagnostics')), axis = 1, inplace = True)\n",
    "dfRad.drop(list(dfRad.filter(regex = 'histogram')), axis = 1, inplace = True)\n",
    "\n",
    "# remove feature sets we don't want to use and remove string from the one that is left\n",
    "dfRad.drop(list(dfRad.filter(regex = 'noNormalize|maskNormalize')), axis = 1, inplace = True)\n",
    "dfRad = dfRad.rename(columns=lambda x: x.replace('normalized_',''))\n",
    "\n",
    "# To match the semantic data file\n",
    "dfRad['StudyPatientName'] = dfRad['StudyPatientName'].str.replace('_',' ')\n",
    "\n",
    "# sensible prefix \n",
    "dfRad = dfRad.rename(columns=lambda x: x.replace('original','radiomics'))\n",
    "\n",
    "# split off the repro rows\n",
    "dfRep1 = dfRad.loc[dfRad.StudyPatientName.str.contains('rep'),:].copy()\n",
    "dfRep1['StudyPatientName'] = dfRep1['StudyPatientName'].str.replace(' repro','')\n",
    "dfRep1.sort_values('StudyPatientName', axis=0, inplace=True)\n",
    "dfRep1.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# remove repro from main data frame\n",
    "dfRad = dfRad.loc[~dfRad.StudyPatientName.str.contains('rep'),:]\n",
    "dfRad.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# main data rows for same patients as repro\n",
    "dfRep0 = dfRad.loc[dfRad['StudyPatientName'].isin(dfRep1['StudyPatientName'])].copy()\n",
    "dfRep0.sort_values('StudyPatientName', axis=0, inplace=True)\n",
    "dfRep0.reset_index(inplace=True, drop=True)\n",
    "\n",
    "for col in dfRep1.drop('StudyPatientName', axis=1):\n",
    "    data = np.stack((dfRep0[col], dfRep1[col]), axis=1)\n",
    "    iccDict[col] = intraclass_correlation(data, \"twoway\", \"agreement\").value\n",
    "\n",
    "# dfRad = dfRad.filter(regex='shape|firstorder|StudyPatientName')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and prepare semantic data (discovery and test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "discoveryFile = os.path.join(dataFolder, 'ECE_Semantic_Data', 'discovery.csv')\n",
    "externalTestFile = os.path.join(dataFolder, 'ECE_Semantic_Data', 'external.csv')\n",
    "    \n",
    "# load data\n",
    "dfTrain = pd.read_csv(discoveryFile)\n",
    "dfTest  = pd.read_csv(externalTestFile)\n",
    "\n",
    "# drop features we are not going to use for classification\n",
    "dfTrain.drop(['Gleason biopsy','TumorGradeMRI'], inplace=True, axis=1)\n",
    "dfTest.drop(['Gleason biopsy','TumorGradeMRI'], inplace=True, axis=1)\n",
    "\n",
    "# change this feature to have a more descriptive name\n",
    "dfTrain.insert(1, 'Gleason>(3+4)', dfTrain['GleasonBinary'])\n",
    "dfTest.insert(1, 'Gleason>(3+4)', dfTest['GleasonBinary'])\n",
    "dfTrain.drop('GleasonBinary', axis=1, inplace=True)\n",
    "dfTest.drop('GleasonBinary', axis=1, inplace=True)\n",
    "\n",
    "# make these features binary 0/1\n",
    "toBinary = ['SmoothCapsularBulging' ,'CapsularDisruption', 'UnsharpMargin', 'IrregularContour', 'BlackEstritionPeripFat', 'MeasurableECE', 'RetroprostaticAngleOblit', 'highsignalT1FS']\n",
    "for tb in toBinary:\n",
    "    dfTrain[tb]  = dfTrain[tb].map(dict(YES=1, NO=0))\n",
    "    dfTest[tb] = dfTest[tb].map(dict(YES=1, NO=0))\n",
    "\n",
    "# simplify PIRADS (as ECE rate for 3 and 4 is around 20% and for 5 is around 75%)\n",
    "dfTrain.insert(4, 'PIRADS>4', (dfTrain['IndLesPIRADS_V2'] > 4).astype(int))\n",
    "dfTrain.drop('IndLesPIRADS_V2', axis=1, inplace=True)\n",
    "dfTest.insert(4, 'PIRADS>4', (dfTest['IndLesPIRADS_V2'] > 4).astype(int))\n",
    "dfTest.drop('IndLesPIRADS_V2', axis=1, inplace=True)\n",
    "\n",
    "# log transform some features to get rid of long tail\n",
    "dfTrain.ProstateVolume = np.log(dfTrain.ProstateVolume)\n",
    "dfTest.ProstateVolume = np.log(dfTest.ProstateVolume)\n",
    "dfTrain.PSA = np.log(dfTrain.PSA)\n",
    "dfTest.PSA = np.log(dfTest.PSA)\n",
    "\n",
    "# is missing in test and training, so replace both with median from the training data\n",
    "psaTrainMedian = np.nanmedian(np.array(dfTrain.PSA))\n",
    "dfTrain.PSA.fillna(psaTrainMedian, inplace=True)\n",
    "dfTest.PSA.fillna(psaTrainMedian, inplace=True)\n",
    "\n",
    "# this feature is not selected in the semantic model, so this has no effect\n",
    "# fill in with the most common value\n",
    "dfTest.highsignalT1FS.fillna(0, inplace=True)\n",
    "\n",
    "# add string to names for easy manipulation of groups\n",
    "clinicalFeatures = ['Gleason>(3+4)', 'ProstateVolume', 'PSA', 'PIRADS>4']\n",
    "semanticFeatures = list(set(dfTrain.columns) - set(clinicalFeatures) - set(['PID', 'ECE_Pathology']))\n",
    "dfTrain = dfTrain.rename(columns=lambda x: 'clinical_' + x if x in clinicalFeatures else x)\n",
    "dfTest = dfTest.rename(columns=lambda x: 'clinical_' + x if x in clinicalFeatures else x)\n",
    "dfTrain = dfTrain.rename(columns=lambda x: 'semantic_' + x if x in semanticFeatures else x)\n",
    "dfTest = dfTest.rename(columns=lambda x: 'semantic_' + x if x in semanticFeatures else x)\n",
    "\n",
    "# merge radiomics \n",
    "dfTrain = dfTrain.merge(dfRad, left_on='PID', right_on='StudyPatientName')\n",
    "dfTest = dfTest.merge(dfRad, left_on='PID', right_on='StudyPatientName')\n",
    "dfTrain = dfTrain.drop(['PID', 'StudyPatientName'], axis=1)\n",
    "dfTest = dfTest.drop(['PID', 'StudyPatientName'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main model fitting function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# some functions to help get smooth ROC and DCA curves for the test data\n",
    "\n",
    "def jitterColumns(df, scale):\n",
    "    for col in df:\n",
    "        df[col] = df[col] + np.random.normal(loc=0, scale=scale*np.std(df[col]), size=df[col].shape)\n",
    "    return df\n",
    "\n",
    "def replicateDf(df, N):\n",
    "    dfOut = df.copy()\n",
    "    for n in range(N-1):\n",
    "        dfOut = pd.concat([dfOut, df], axis=0)\n",
    "    return dfOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fitModel(dfTrain, dfTest, pipeline, coefDisplayFunction=None, keepRegex=None, dropList = None, permutationTest=False, jitterTestData=False, crossValidate=True):\n",
    "\n",
    "    # reproducible execution\n",
    "    seed = 42\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # get training and test data\n",
    "    XTrain = dfTrain.drop('ECE_Pathology', axis=1)\n",
    "    XTest = dfTest.drop('ECE_Pathology', axis=1)\n",
    "    yTrain = dfTrain.ECE_Pathology\n",
    "    yTest = dfTest.ECE_Pathology\n",
    "    \n",
    "    # keep features as indicated\n",
    "    if keepRegex is not None:\n",
    "        XTrain = XTrain.filter(regex = keepRegex)\n",
    "        XTest = XTest.filter(regex = keepRegex)\n",
    "        \n",
    "    # discard features listed\n",
    "    if dropList is not None:\n",
    "        XTrain.drop(dropList, axis=1, inplace=True)\n",
    "        XTest.drop(dropList, axis=1, inplace=True)\n",
    "     \n",
    "    print(XTrain.columns)\n",
    "    \n",
    "    # make sure correlationSelector will not remove any clinical or semantic features\n",
    "    if pipeline.steps[0][0] == 'correlationSelector':\n",
    "        pipeline.steps[0][1].namedColumnsKeep = [x for x in XTrain.columns if 'clinical' in x or 'semantic' in x]\n",
    "        \n",
    "    # drop low variance radiomics features (in practice this only includes radiomics_glcm_Idmn)\n",
    "    CoV = pd.DataFrame(XTrain.apply(lambda x: np.std(x)/(0.0001 + np.mean(x)), axis=0))\n",
    "    lowVarianceFeatures = CoV.loc[np.abs(CoV.loc[:,0])<0.01,:].index.values.tolist()\n",
    "    lowVarianceFeatures = [x for x in lowVarianceFeatures if 'clinical' not in x and 'semantic' not in x]\n",
    "    XTrain.drop(lowVarianceFeatures, axis = 1, inplace = True)\n",
    "    XTest.drop(lowVarianceFeatures, axis = 1, inplace = True)\n",
    "\n",
    "    # fit to all data\n",
    "    pipeline.fit(XTrain, yTrain)\n",
    "\n",
    "    if crossValidate:\n",
    "        # cross-validate\n",
    "        outer_cv = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats)\n",
    "        cv_result = cross_validate(pipeline, \n",
    "                                   XTrain, \n",
    "                                   yTrain, \n",
    "                                   cv=outer_cv, \n",
    "                                   scoring=scorers,\n",
    "                                   return_estimator=True, \n",
    "                                   verbose=0, \n",
    "                                   n_jobs=-1)\n",
    "\n",
    "        # print CV scores\n",
    "        AUC_CV = np.mean(cv_result['test_roc_auc'])\n",
    "        Accuracy_CV = np.mean(cv_result['test_accuracy'])\n",
    "        F1_CV = np.mean(cv_result['test_f1'])\n",
    "        print('AUCROC   (CV) = ' + str(AUC_CV.round(3)) + ' \\u00B1 ' + str(np.round(np.std(cv_result['test_roc_auc']),3)))\n",
    "        print('Accuracy (CV) = ' + str(Accuracy_CV.round(3)) + ' \\u00B1 ' + str(np.round(np.std(cv_result['test_accuracy']),3)))\n",
    "        print('F1       (CV) = ' + str(F1_CV.round(3)) + ' \\u00B1 ' + str(np.round(np.std(cv_result['test_f1']),3)))\n",
    "\n",
    "        FNR_CV, FPR_CV, DCA_CV = unpack_scorers(cv_result)\n",
    "    else:\n",
    "        cv_result, AUC_CV, Accuracy_CV, F1_CV, FNR_CV, FPR_CV, DCA_CV = None, None, None, None, None, None, None\n",
    "        \n",
    "\n",
    "    # permutation testing\n",
    "    if permutationTest:\n",
    "        outer_cv.n_repeats = 1\n",
    "\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "        #\n",
    "        scoreDirect, perm_scores, pValueDirect = permutation_test_score(pipeline, \n",
    "                                                                        XTrain, \n",
    "                                                                        yTrain, \n",
    "                                                                        scoring=\"roc_auc\",\n",
    "                                                                        cv=outer_cv, \n",
    "                                                                        n_permutations=n_permutations,\n",
    "                                                                        verbose=0, n_jobs=-1)\n",
    "        #\n",
    "        warnings.simplefilter('default')\n",
    "        os.environ[\"PYTHONWARNINGS\"] = 'default'\n",
    "\n",
    "        # pValueDirect is computed using scoreDirect and assumes only one outer CV run\n",
    "        # We have used repeated outer CV, so the following code correctly computes the p-value of our repeated CV performance estimate\n",
    "        # Actually, it doesn't seem to make much difference, so am relaxed about that.\n",
    "\n",
    "        p_values = []\n",
    "        scores_roc_auc = np.mean(np.reshape(cv_result['test_roc_auc'], (n_repeats, -1)), axis=1)\n",
    "        for score in scores_roc_auc:\n",
    "            p_values.append((np.count_nonzero(perm_scores >= score) + 1) / (n_permutations + 1))\n",
    "        pValue_CV = np.mean(p_values)\n",
    "        print('p-value       = ' + str(pValue_CV.round(4)))\n",
    "    else:\n",
    "        pValue_CV = None\n",
    "    \n",
    "    # replicate and add jitter to test data to give smoother roc and DCA curves\n",
    "    if jitterTestData:\n",
    "        XTest = replicateDf(XTest, 20)\n",
    "        yTest = replicateDf(yTest, 20)\n",
    "        XTest = jitterColumns(XTest, 0.1)\n",
    "\n",
    "    # get scores and predicted class info\n",
    "    test_score = pipeline.predict_proba(XTest)[:, 1]\n",
    "    test_class = pipeline.predict(XTest)\n",
    "\n",
    "    # test scores from main model\n",
    "    testAUROC = roc_auc_score(yTest, test_score)\n",
    "    testAccuracy = accuracy_score(yTest, test_class)\n",
    "    testF1 = f1_score(yTest, test_class)\n",
    "\n",
    "    pValueTest = mannwhitneyu(test_score[yTest==0], test_score[yTest==1], alternative='two-sided').pvalue\n",
    "\n",
    "    # print the test performance metrics\n",
    "    print('\\nAUCROC   (test) = ' + str(np.round(testAUROC,3)))\n",
    "    print('Accuracy (test) = ' + str(np.round(testAccuracy,3)))\n",
    "    print('F1       (test) = ' + str(np.round(testF1,3)))\n",
    "    print('p-value  (test) = ' + str(np.round(pValueTest, 6)))\n",
    "\n",
    "    if coefDisplayFunction is not None:\n",
    "        dfCoefResults = coefDisplayFunction(pipeline, XTrain.columns, cv_result)\n",
    "\n",
    "    out = {'test_AUC':testAUROC,\n",
    "           'test_score':test_score,\n",
    "           'test_class':test_class,\n",
    "           'test_accuracy':testAccuracy,\n",
    "           'test_f1':testF1,\n",
    "           'test_pValue':pValueTest,\n",
    "           'AUC_CV':AUC_CV,\n",
    "           'Accuracy_CV':Accuracy_CV,\n",
    "           'F1_CV':F1_CV,\n",
    "           'pValue_CV':pValue_CV,\n",
    "           'FNR_CV':FNR_CV,\n",
    "           'FPR_CV':FPR_CV,\n",
    "           'DCA_CV':DCA_CV,\n",
    "           'XTrain':XTrain.copy(),\n",
    "           'XTest':XTest.copy(),\n",
    "           'yTrain':yTrain.copy(),\n",
    "           'yTest':yTest.copy(),\n",
    "           'pipeline':pipeline,\n",
    "           'cv_result':cv_result\n",
    "          }\n",
    "    \n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some logistic regression pipelines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# basic logistic regression, no regularisation\n",
    "pipelineLRsimple = Pipeline(steps=[('scaler', StandardScaler()),\n",
    "                                   ('lr', LogisticRegression(penalty='none'))])\n",
    "\n",
    "# logistic regression with lasso\n",
    "pipelineLRlasso = Pipeline(steps=[('scaler', StandardScaler()), \n",
    "                                  ('lr', LogisticRegressionCV(Cs=20, \n",
    "                                                              cv=10, \n",
    "                                                              solver=\"liblinear\",\n",
    "                                                              max_iter=10000, \n",
    "                                                              penalty='l1',\n",
    "                                                              random_state=42))])\n",
    "\n",
    "# logistic regression with ridge\n",
    "pipelineLRridge = Pipeline(steps=[('scaler', StandardScaler()), \n",
    "                                  ('lr', LogisticRegressionCV(Cs=20, \n",
    "                                                              cv=10, \n",
    "                                                              solver=\"liblinear\",\n",
    "                                                              max_iter=10000, \n",
    "                                                              penalty='l2',\n",
    "                                                              random_state=42))])\n",
    "\n",
    "\n",
    "# logistic regression with lasso, preceded by correlation feature reduction\n",
    "# fitModel function will modify pipeline to make sure the clinical and semantic features are not affected by\n",
    "# correlation feature reduction\n",
    "pipelineCfrLRlasso = Pipeline([('correlationSelector', featSelCorr(threshold=0.9,\n",
    "                                                                   exact=False,\n",
    "                                                                   featureGroupHierarchy=['shape_MeshVolume',\n",
    "                                                                                          'shape',\n",
    "                                                                                          'firstorder'])),\n",
    "                               ('scaler', StandardScaler()),\n",
    "                               ('lr', GridSearchCV(estimator=LogisticRegression(solver=\"liblinear\", \n",
    "                                                                                max_iter=10000, \n",
    "                                                                                penalty='l1'), \n",
    "                                                   param_grid={'C':np.logspace(np.log10(0.05), np.log10(50), 20)}, \n",
    "                                                   cv=StratifiedKFold(n_splits=10), \n",
    "                                                   refit=True, \n",
    "                                                   verbose=0, \n",
    "                                                   scoring='neg_log_loss', \n",
    "                                                   n_jobs=1))])\n",
    "\n",
    "# logistic regression with ridge, preceded by correlation feature reduction\n",
    "# fitModel function will modify pipeline to make sure the clinical and semantic features are not affected by\n",
    "# correlation feature reduction\n",
    "pipelineCfrLRridge = Pipeline([('correlationSelector', featSelCorr(threshold=0.9,\n",
    "                                                                   exact=False,\n",
    "                                                                   featureGroupHierarchy=['shape_MeshVolume',\n",
    "                                                                                          'shape',\n",
    "                                                                                          'firstorder'])),\n",
    "                               ('scaler', StandardScaler()),\n",
    "                               ('lr', GridSearchCV(estimator=LogisticRegression(solver=\"liblinear\", \n",
    "                                                                                max_iter=10000, \n",
    "                                                                                penalty='l2'), \n",
    "                                                   param_grid={'C':np.logspace(np.log10(0.05), np.log10(50), 20)}, \n",
    "                                                   cv=StratifiedKFold(n_splits=10), \n",
    "                                                   refit=True, \n",
    "                                                   verbose=0, \n",
    "                                                   scoring='neg_log_loss', \n",
    "                                                   n_jobs=1))])\n",
    "\n",
    "# logistic regression with lasso using GridSearchCV\n",
    "pipelineLRlasso2 = Pipeline([('scaler', StandardScaler()),\n",
    "                                ('lr', GridSearchCV(estimator=LogisticRegression(solver=\"liblinear\", \n",
    "                                                                                 max_iter=10000, \n",
    "                                                                                 penalty='l1'), \n",
    "                                                    param_grid={'C':np.logspace(np.log10(1e-4), np.log10(1e4), 20)}, \n",
    "                                                    cv=StratifiedKFold(n_splits=10), \n",
    "                                                    refit=True, \n",
    "                                                    verbose=0, \n",
    "                                                    scoring='neg_log_loss', \n",
    "                                                    n_jobs=1))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to display non-zero logistic regression coeffients for the pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def coefDispFunLRsimple(pipeline, featureNames, dummy):\n",
    "    dfCoefResults = pd.DataFrame({'Feature':[x.replace('clinical_','') for x in featureNames], \n",
    "                                  'Coeff':np.squeeze(pipeline._final_estimator.coef_)})\n",
    "    dfCoefResults.sort_values(by='Coeff', key=abs, inplace=True, ascending=False)\n",
    "    if '3.6.' in sys.version:\n",
    "        display(dfCoefResults.style.hide_index())\n",
    "    else:\n",
    "        display(dfCoefResults)\n",
    "#     print(dfCoefResults.to_string(index=False))\n",
    "\n",
    "def coefDispFunLRlasso(pipeline, featureNames, cv_result):\n",
    "\n",
    "    # get frequency that features are non-zero across the repeated cv splits\n",
    "    if cv_result is not None:\n",
    "        coef_cv = np.zeros((len(cv_result['estimator']), len(featureNames)))\n",
    "        for n, res in enumerate(cv_result['estimator']):\n",
    "            coef_cv[n, :] = res._final_estimator.coef_\n",
    "        coef_freq = np.sum(coef_cv != 0, axis=0) / (n_repeats * n_splits)\n",
    "    else:\n",
    "        coef_freq = [0]*len(featureNames)\n",
    "        \n",
    "    # put icc values in array for including in DataFrame\n",
    "    iccList = []\n",
    "    for feat in featureNames:\n",
    "        if feat in iccDict:\n",
    "            iccList.append(iccDict[feat])\n",
    "        else:\n",
    "            iccList.append('-')\n",
    "\n",
    "    # simplify feature names\n",
    "    featureNames = [x.replace('clinical_','') for x in featureNames]\n",
    "    featureNames = [x.replace('semantic_','') for x in featureNames]\n",
    "    featureNames = [x.replace('radiomics_','') for x in featureNames]\n",
    "            \n",
    "    # display sorted coefficients and selection frequency\n",
    "    coeffs = np.squeeze(pipeline._final_estimator.coef_)\n",
    "    dfCoefResults = pd.DataFrame({'Feature': featureNames, 'Coeff': coeffs, 'Freq': coef_freq, 'ICC':iccList})\n",
    "    dfCoefResults.sort_values(by=['Coeff', 'Freq'], key=abs, inplace=True, ascending=False)\n",
    "    if '3.6.' in sys.version:\n",
    "        display(dfCoefResults.loc[dfCoefResults.Coeff != 0, :].style.hide_index())\n",
    "    else:\n",
    "        display(dfCoefResults.loc[dfCoefResults.Coeff != 0, :])\n",
    "#     print(dfCoefResults.loc[dfCoefResults.Coeff != 0, :].to_string(index=False))\n",
    "\n",
    "def coefDispFunCfrLRlasso(pipeline, featureNames, cv_result):\n",
    "    \n",
    "    # get frequency that features are non-zero across the repeated cv splits\n",
    "    if cv_result is not None:\n",
    "        coef_cv = np.zeros((len(cv_result['estimator']), len(featureNames)))\n",
    "        fs_mask = np.zeros((len(cv_result['estimator']), len(featureNames)))\n",
    "        for n, res in enumerate(cv_result['estimator']):\n",
    "            fs_mask[n, :] = res.steps[0][1].mask_\n",
    "            coef_cv[n, res.steps[0][1].mask_] = res._final_estimator.best_estimator_.coef_\n",
    "        coef_freq = np.sum(coef_cv != 0, axis=0) / (n_repeats * n_splits)\n",
    "    else:\n",
    "        coef_freq = [0]*len(featureNames)\n",
    "\n",
    "    # put icc values in array for including in DataFrame\n",
    "    iccList = []\n",
    "    for feat in featureNames:\n",
    "        if feat in iccDict:\n",
    "            iccList.append(iccDict[feat])\n",
    "        else:\n",
    "            iccList.append('-')\n",
    "\n",
    "    # simplify feature names\n",
    "    featureNames = [x.replace('clinical_','') for x in featureNames]\n",
    "    featureNames = [x.replace('semantic_','') for x in featureNames]\n",
    "    featureNames = [x.replace('radiomics_','') for x in featureNames]\n",
    "            \n",
    "    # display sorted coefficients and selection frequency\n",
    "    coeffs = np.zeros(len(featureNames))\n",
    "    coeffs[pipeline.steps[0][1].mask_] = np.squeeze(pipeline._final_estimator.best_estimator_.coef_)\n",
    "\n",
    "    dfCoefResults = pd.DataFrame({'Feature': featureNames, 'Coeff': coeffs, 'Freq': coef_freq, 'ICC':iccList})\n",
    "    dfCoefResults.sort_values(by=['Coeff', 'Freq'], key=abs, inplace=True, ascending=False)\n",
    "    if '3.6.' in sys.version:\n",
    "        display(dfCoefResults.loc[dfCoefResults.Coeff != 0, :].style.hide_index())\n",
    "    else:\n",
    "        display(dfCoefResults.loc[dfCoefResults.Coeff != 0, :])\n",
    "#     print(dfCoefResults.loc[dfCoefResults.Coeff != 0, :].to_string(index=False))\n",
    "\n",
    "def coefDispFunLRlasso2(pipeline, featureNames, cv_result):\n",
    "\n",
    "    # get frequency that features are non-zero across the repeated cv splits\n",
    "    if cv_result is not None:\n",
    "        coef_cv = np.zeros((len(cv_result['estimator']), len(featureNames)))\n",
    "        for n, res in enumerate(cv_result['estimator']):\n",
    "            coef_cv[n, :] = res.steps[1][1].best_estimator_.coef_\n",
    "        coef_freq = np.sum(coef_cv != 0, axis=0) / (n_repeats * n_splits)\n",
    "    else:\n",
    "        coef_freq = [0]*len(featureNames)\n",
    "        \n",
    "    # put icc values in array for including in DataFrame\n",
    "    iccList = []\n",
    "    for feat in featureNames:\n",
    "        if feat in iccDict:\n",
    "            iccList.append(iccDict[feat])\n",
    "        else:\n",
    "            iccList.append('-')\n",
    "\n",
    "    # simplify feature names\n",
    "    featureNames = [x.replace('clinical_','') for x in featureNames]\n",
    "    featureNames = [x.replace('semantic_','') for x in featureNames]\n",
    "    featureNames = [x.replace('radiomics_','') for x in featureNames]\n",
    "            \n",
    "    # display sorted coefficients and selection frequency\n",
    "    coeffs = np.squeeze(pipeline._final_estimator.best_estimator_.coef_)\n",
    "    dfCoefResults = pd.DataFrame({'Feature': featureNames, 'Coeff': coeffs, 'Freq': coef_freq, 'ICC':iccList})\n",
    "    dfCoefResults.sort_values(by=['Coeff', 'Freq'], key=abs, inplace=True, ascending=False)\n",
    "    if '3.6.' in sys.version:\n",
    "        display(dfCoefResults.loc[dfCoefResults.Coeff != 0, :].style.hide_index())\n",
    "    else:\n",
    "        display(dfCoefResults.loc[dfCoefResults.Coeff != 0, :])\n",
    "#     print(dfCoefResults.loc[dfCoefResults.Coeff != 0, :].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for SHAP beeswarm plots for the pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def showShapLR(r, file=None):\n",
    "    standardiser = r['pipeline'].steps[0][1]\n",
    "\n",
    "    X = pd.DataFrame(columns=r['XTest'].columns, data=standardiser.transform(r['XTest'].copy()))\n",
    "    X = X.rename(columns=lambda x: x.replace('clinical_',''))\n",
    "    X = X.rename(columns=lambda x: x.replace('semantic_',''))\n",
    "    X = X.rename(columns=lambda x: x.replace('radiomics_',''))\n",
    "    \n",
    "    \n",
    "    explainer = shap.explainers.Linear(r['pipeline']._final_estimator, X)\n",
    "    shap_values = explainer(X)\n",
    "    max_display = 1 + np.sum(r['pipeline']._final_estimator.coef_ != 0)\n",
    "    shap.plots.beeswarm(shap_values, max_display=max_display, show=False)\n",
    "\n",
    "    if file is not None:\n",
    "        plt.savefig(file, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# use this version when LR tuning done uing GridSearch\n",
    "def showShapLR2(r, file=None):\n",
    "    standardiser = r['pipeline'].steps[0][1]\n",
    "\n",
    "    # get final estimator and refit to the non-zero coefficients\n",
    "#     estimator = r['pipeline']._final_estimator.best_estimator_.copy()\n",
    "#     coef = \n",
    "#     estimator.fit(r['XTrain'], r['yTrain'])\n",
    "\n",
    "    X = pd.DataFrame(columns=r['XTest'].columns, data=standardiser.transform(r['XTest'].copy()))\n",
    "    X = X.rename(columns=lambda x: x.replace('clinical_',''))\n",
    "    X = X.rename(columns=lambda x: x.replace('semantic_',''))\n",
    "    X = X.rename(columns=lambda x: x.replace('radiomics_',''))\n",
    "    \n",
    "    \n",
    "    explainer = shap.explainers.Linear(r['pipeline']._final_estimator.best_estimator_, X)\n",
    "    shap_values = explainer(X)\n",
    "    max_display = 1 + np.sum(r['pipeline']._final_estimator.best_estimator_.coef_ != 0)\n",
    "    shap.plots.beeswarm(shap_values, max_display=max_display, show=False)\n",
    "\n",
    "    if file is not None:\n",
    "        plt.savefig(file, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def showShapLRcfr(r, file=None):\n",
    "\n",
    "    mask = r['pipeline'].steps[0][1].mask_\n",
    "    standardiser = r['pipeline'].steps[1][1]\n",
    "\n",
    "    X = r['XTest'].loc[:,mask]\n",
    "    X = standardiser.transform(X)\n",
    "    X = pd.DataFrame(columns=r['XTest'].columns[mask], data=X)\n",
    "    X = X.rename(columns=lambda x: x.replace('clinical_',''))\n",
    "    X = X.rename(columns=lambda x: x.replace('semantic_',''))\n",
    "    X = X.rename(columns=lambda x: x.replace('radiomics_',''))\n",
    "    \n",
    "    model = r['pipeline']._final_estimator.best_estimator_\n",
    "    explainer = shap.explainers.Linear(model, X)\n",
    "    shap_values = explainer(X)\n",
    "    max_display = 1 + np.sum(model.coef_ != 0)\n",
    "    shap.plots.beeswarm(shap_values, max_display=max_display, show=False)\n",
    "\n",
    "    if file is not None:\n",
    "        plt.savefig(file, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit models to four combinations of input features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "jitterTestData = False\n",
    "\n",
    "# for figure naming\n",
    "if jitterTestData:\n",
    "    jitterStr = '_testJitter'\n",
    "else:\n",
    "    jitterStr = ''\n",
    "    \n",
    "models = []\n",
    "\n",
    "print('Clinical features\\n')\n",
    "rc = fitModel(dfTrain,\n",
    "              dfTest,\n",
    "              pipelineLRsimple, \n",
    "              coefDisplayFunction=coefDispFunLRsimple, \n",
    "              keepRegex='clinical',\n",
    "              permutationTest=permutationTest,\n",
    "              jitterTestData=jitterTestData,\n",
    "              crossValidate=crossValidate)\n",
    "rc['label'] = 'Clinical'\n",
    "if not jitterTestData:\n",
    "    showShapLR(rc) #, file=os.path.join(dataFolder, 'figures', 'shap_clinical.pdf'))\n",
    "models.append(rc)\n",
    "\n",
    "print('\\n\\n\\nClinical + Radiomic features\\n')\n",
    "rcr = fitModel(dfTrain,\n",
    "               dfTest,\n",
    "               pipelineCfrLRlasso, \n",
    "               coefDisplayFunction=coefDispFunCfrLRlasso, \n",
    "               keepRegex='clinical|radiomic', \n",
    "               permutationTest=permutationTest,\n",
    "               jitterTestData=jitterTestData,\n",
    "               crossValidate=crossValidate)\n",
    "rcr['label'] = 'Clinical + Radiomic'\n",
    "if not jitterTestData:\n",
    "    showShapLRcfr(rcr) #, file=os.path.join(dataFolder, 'figures', 'shap_clinical_radiomic.pdf'))\n",
    "models.append(rcr)\n",
    "\n",
    "for dropList in [[], ['semantic_MeasurableECE']]:\n",
    "\n",
    "    label = 'Clinical + Semantic'\n",
    "    if len(dropList)>0:\n",
    "        label += ' - MeasECE'\n",
    "    print('\\n\\n\\n' + label + '\\n')\n",
    "    rcs = fitModel(dfTrain,\n",
    "                   dfTest,\n",
    "                   pipelineLRlasso, \n",
    "                   coefDisplayFunction=coefDispFunLRlasso, \n",
    "                   keepRegex='clinical|semantic', \n",
    "                   dropList=dropList,\n",
    "                   permutationTest=permutationTest,\n",
    "                   jitterTestData=jitterTestData,\n",
    "                   crossValidate=crossValidate)\n",
    "    rcs['label'] = label\n",
    "    \n",
    "    if not jitterTestData:\n",
    "        showShapLR(rcs) #, file=os.path.join(dataFolder, 'figures', 'shap_clinical_semantic.pdf'))\n",
    "    models.append(rcs.copy())\n",
    "\n",
    "\n",
    "    label = 'Clinical + Semantic + Radiomic'\n",
    "    if len(dropList)>0:\n",
    "        label += ' - MeasECE'\n",
    "    print('\\n\\n\\n' + label + '\\n')\n",
    "    rcsr = fitModel(dfTrain,\n",
    "                    dfTest,\n",
    "                    pipelineCfrLRlasso, \n",
    "                    coefDisplayFunction=coefDispFunCfrLRlasso, \n",
    "                    keepRegex='clinical|semantic|radiomic', \n",
    "                    dropList=dropList,\n",
    "                    permutationTest=permutationTest,\n",
    "                    jitterTestData=jitterTestData,\n",
    "                    crossValidate=crossValidate)\n",
    "    rcsr['label'] = label\n",
    "    if not jitterTestData:\n",
    "        showShapLRcfr(rcsr) #, file=os.path.join(dataFolder, 'figures', 'shap_clinical_semantic_radiomic.pdf'))\n",
    "    models.append(rcsr.copy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make some plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(12,12))\n",
    "ax = ax.ravel()\n",
    "\n",
    "# discovery data plots\n",
    "\n",
    "if crossValidate:\n",
    "        # ROC\n",
    "    for r in models:\n",
    "        ax[0].plot(r['FPR_CV']['values'], \n",
    "                   [1-x for x in r['FNR_CV']['values']], \n",
    "                   label = 'AUC = ' + str(np.round(r['AUC_CV'],3)) + ' ' + r['label'])\n",
    "    ax[0].set_xlabel('1 - Specificity', fontsize=14)\n",
    "    ax[0].set_ylabel('Sensitivity', fontsize=14)\n",
    "    ax[0].set_title('ROC', fontsize=16, fontweight='bold')\n",
    "    ax[0].legend(fontsize=9)\n",
    "    ax[0].text(-0.3, 0.5, 'Discovery data, cross-validated', fontsize=16, fontweight='bold', rotation=90, verticalalignment='center')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # DCA\n",
    "    TPtrain = np.sum(dfTrain.ECE_Pathology==1)/dfTrain.shape[0]\n",
    "    FPtrain = np.sum(dfTrain.ECE_Pathology==0)/dfTrain.shape[0]\n",
    "    for r in models:\n",
    "        exactScale = TPtrain/r['DCA_CV']['values'][0]\n",
    "        ax[1].plot(r['DCA_CV']['thresholds'], [x*exactScale for x in r['DCA_CV']['values']], label=r['label'])\n",
    "    # add treat all and treat none\n",
    "    pt = np.array(rc['DCA_CV']['thresholds'])\n",
    "    ax[1].plot(pt, (TPtrain - FPtrain*pt/(1-pt)), label='Treat all', color='k', linestyle='--')\n",
    "    ax[1].plot([0, 1], [0, 0], label='Treat none', color='k', linestyle=':')\n",
    "\n",
    "    ax[1].set_title('Net benefit curve', fontsize=16, fontweight='bold')\n",
    "    ax[1].legend(fontsize=9)\n",
    "    ax[1].set_xlabel('Threshold', fontsize=14)\n",
    "    ax[1].set_ylabel('Net benefit curve', fontsize=14)\n",
    "    ax[1].set_ylim([-0.2, 0.4])\n",
    "    ax[1].set_xlim([0, 1])\n",
    "                        \n",
    "# test data plots\n",
    "\n",
    "# ROC\n",
    "for r in models:\n",
    "    fpr, tpr, _ = roc_curve(r['yTest'], r['test_score'])\n",
    "    ax[2].plot(fpr, tpr, label='AUC = ' + str(np.round(r['test_AUC'],3)) + ' ' + r['label'])\n",
    "ax[2].set_xlabel('1 - Specificity', fontsize=14)\n",
    "ax[2].set_ylabel('Sensitivity', fontsize=14)\n",
    "ax[2].text(-0.3, 0.5, 'Test data', fontsize=16, fontweight='bold', rotation=90, verticalalignment='center')\n",
    "\n",
    "# default model using semantic_MeasurableECE\n",
    "tn, fp, fn, tp = confusion_matrix(dfTest['ECE_Pathology'], dfTest['semantic_MeasurableECE']).ravel()\n",
    "ax[2].plot(fp/(fp+tn), 1-fn/(fn+tp), marker='o', label='MeasurableECE')\n",
    "ax[2].legend(fontsize=9)\n",
    "\n",
    "\n",
    "# FNR, FPR and DCA\n",
    "for r in models:\n",
    "    thresh = np.unique(r['test_score'])\n",
    "    thresh = np.append(thresh, 1e-6)\n",
    "    thresh = np.append(thresh, 1-1e-6)\n",
    "    thresh = np.sort(thresh)\n",
    "    tn, fp, fn, tp = confusion_matrix_thresholds(r['yTest'], r['test_score'], thresh)\n",
    "    ax[3].plot(thresh, (tp - fp * (thresh / (1 - thresh))) / len(r['yTest']), label=r['label'])\n",
    "ax[3].plot(thresh, (tp[0] - fp[0] * (thresh / (1 - thresh))) / len(r['yTest']), label='Treat all', color='k', linestyle='--')\n",
    "ax[3].plot([0, 1], [0, 0], label='Treat none', color='k', linestyle=':')\n",
    "\n",
    "ax[3].legend(fontsize=9)\n",
    "ax[3].set_xlabel('Threshold', fontsize=14)\n",
    "ax[3].set_ylabel('Net benefit', fontsize=14)\n",
    "ax[3].set_ylim([-0.2, 0.4])\n",
    "ax[3].set_xlim([0, 1.0])\n",
    "\n",
    "\n",
    "# figFile = os.path.join(dataFolder, 'figures', 'ROC_NetBenefit' + jitterStr + '.pdf')\n",
    "# plt.savefig(figFile)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(12,12))\n",
    "ax = ax.ravel()\n",
    "\n",
    "# discovery data plots\n",
    "\n",
    "models = [rc, rcs, rcr, rcsr]\n",
    "\n",
    "if crossValidate:\n",
    "    # FNR\n",
    "    for r in models:\n",
    "        ax[0].plot(r['FNR_CV']['thresholds'], r['FNR_CV']['values'], label=r['label'])\n",
    "    ax[0].set_title('False negative rate', fontsize=16, fontweight='bold')\n",
    "    ax[0].legend(fontsize=11)\n",
    "    ax[0].set_xlabel('Threshold', fontsize=14)\n",
    "    ax[0].set_ylabel('False negative rate', fontsize=14)\n",
    "    ax[0].text(-0.3, 0.5, 'Discovery data, cross-validated', fontsize=16, fontweight='bold', rotation=90, verticalalignment='center')\n",
    "\n",
    "    # FPR\n",
    "    for r in models:\n",
    "        ax[1].plot(r['FPR_CV']['thresholds'], r['FPR_CV']['values'], label=r['label'])\n",
    "    ax[1].set_title('False positive rate', fontsize=16, fontweight='bold')\n",
    "    ax[1].legend(fontsize=11)\n",
    "    ax[1].set_xlabel('Threshold', fontsize=14)\n",
    "    ax[1].set_ylabel('False positive rate', fontsize=14)\n",
    "\n",
    "\n",
    "# test data plots\n",
    "\n",
    "# FNR, FPR and DCA\n",
    "for r in models:\n",
    "    thresh = np.unique(r['test_score'])\n",
    "    thresh = np.append(thresh, 1e-6)\n",
    "    thresh = np.append(thresh, 1-1e-6)\n",
    "    thresh = np.sort(thresh)\n",
    "    tn, fp, fn, tp = confusion_matrix_thresholds(r['yTest'], r['test_score'], thresh)\n",
    "    ax[2].plot(thresh, fn/(fn + tp), label=r['label'])\n",
    "    ax[3].plot(thresh, fp/(fp + tn), label=r['label'])\n",
    "\n",
    "\n",
    "ax[2].text(-0.3, 0.5, 'Test data', fontsize=16, fontweight='bold', rotation=90, verticalalignment='center')\n",
    "\n",
    "for axi in [2, 3]:\n",
    "    ax[axi].legend(fontsize=9)\n",
    "    ax[axi].set_xlabel('Threshold', fontsize=14)\n",
    "\n",
    "ax[2].set_ylabel('False negative rate', fontsize=14)\n",
    "ax[3].set_ylabel('False positive rate', fontsize=14)\n",
    "\n",
    "# figFile = os.path.join(dataFolder, 'figures', 'FP_FN' + jitterStr + '.pdf')\n",
    "# plt.savefig(figFile)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if not jitterTestData:\n",
    "    pValue = 10**delong_roc_test(rc['yTest'], rcs['test_score'], rcsr['test_score'])[0,0]\n",
    "    print('Delong comparing clinical + semantic vs. clinical + semantic + radiomic\\np = ' + str(np.round(pValue,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from deepchecks.tabular import Dataset\n",
    "target = 'ECE_Pathology'\n",
    "\n",
    "train_dataset = Dataset(dfTrain.filter(regex = 'clinical|semantic|ECE_Pathology', axis = 1), label=target) #, cat_features=features)\n",
    "test_dataset = Dataset(dfTest.filter(regex = 'clinical|semantic|ECE_Pathology', axis = 1), label=target) #, cat_features=features)\n",
    "\n",
    "# train_dataset = Dataset(dfTrain, label=target, cat_features=features)\n",
    "# test_dataset = Dataset(dfTest, label=target, cat_features=features)\n",
    "\n",
    "from deepchecks.tabular.checks import TrainTestFeatureDrift\n",
    "\n",
    "check = TrainTestFeatureDrift()\n",
    "result = check.run(train_dataset=train_dataset, test_dataset=test_dataset, model=rcs['pipeline'])\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from deepchecks.tabular.checks import TrainTestLabelDrift\n",
    "check = TrainTestLabelDrift()\n",
    "result = check.run(train_dataset=train_dataset, test_dataset=test_dataset)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(dfTrain['semantic_MeasurableECE'],dfTrain['clinical_Gleason>(3+4)'])/dfTrain.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(dfTest['semantic_MeasurableECE'],dfTest['clinical_Gleason>(3+4)'])/dfTest.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCheck = pd.concat([dfTest,dfTrain],axis=0)\n",
    "testTrain = np.ones(dfCheck.shape[0])\n",
    "testTrain[0:dfTest.shape[0]] = 0\n",
    "dfCheck['ECE_Pathology'] = testTrain\n",
    "\n",
    "rCheck = fitModel(dfCheck,\n",
    "               dfCheck,\n",
    "               pipelineLRlasso, \n",
    "               coefDisplayFunction=coefDispFunLRlasso, \n",
    "               keepRegex='clinical|semantic_MeasurableECE|semantic_IrregularContour|semantic_CapsularDisruption|ECE_Pathology', \n",
    "               permutationTest=permutationTest,\n",
    "               jitterTestData=jitterTestData,\n",
    "               crossValidate=crossValidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCheck.filter(regex='clinical|semantic_MeasurableECE|semantic_IrregularContour|semantic_CapsularDisruption|ECE_Pathology')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcheck = fitModel(dfTrain,\n",
    "              dfTest,\n",
    "              pipelineLRsimple, \n",
    "              coefDisplayFunction=coefDispFunLRsimple, \n",
    "              keepRegex='semantic_MeasurableECE|clinical_Gleason\\>\\(3\\+4\\)', \n",
    "              permutationTest=permutationTest,\n",
    "              jitterTestData=jitterTestData,\n",
    "              crossValidate=crossValidate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSim = pd.DataFrame({'clinical_Gleason>(3+4)':[0, 0, 1, 1], 'semantic_MeasurableECE':[0, 1, 0, 1]})\n",
    "np.reshape(rcheck['pipeline'].predict_proba(dfSim)[:,1],(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.precision', 3)\n",
    "\n",
    "dfHere = dfTrain.copy()\n",
    "dfHere.rename(columns={'semantic_MeasurableECE':'MeasurableECE', 'clinical_Gleason>(3+4)':'Gleason>3+4'}, inplace=True)\n",
    "ct0 = pd.crosstab(dfHere.loc[dfHere['ECE_Pathology']==0, 'Gleason>3+4'], dfHere.loc[dfHere['ECE_Pathology']==0, 'MeasurableECE'])\n",
    "ct1 = pd.crosstab(dfHere.loc[dfHere['ECE_Pathology']==1, 'Gleason>3+4'], dfHere.loc[dfHere['ECE_Pathology']==1, 'MeasurableECE'])\n",
    "ct1/(ct1+ct0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfHere = dfTest.copy()\n",
    "dfHere.rename(columns={'semantic_MeasurableECE':'MeasurableECE', 'clinical_Gleason>(3+4)':'Gleason>3+4'}, inplace=True)\n",
    "ct0 = pd.crosstab(dfHere.loc[dfHere['ECE_Pathology']==0, 'Gleason>3+4'], dfHere.loc[dfHere['ECE_Pathology']==0, 'MeasurableECE'])\n",
    "ct1 = pd.crosstab(dfHere.loc[dfHere['ECE_Pathology']==1, 'Gleason>3+4'], dfHere.loc[dfHere['ECE_Pathology']==1, 'MeasurableECE'])\n",
    "ct1/(ct1+ct0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfHere = dfTrain.copy()\n",
    "cm0 = confusion_matrix(dfHere.loc[dfHere['ECE_Pathology']==0,'clinical_Gleason>(3+4)'], dfHere.loc[dfHere['ECE_Pathology']==0,'semantic_MeasurableECE'])\n",
    "cm1 = confusion_matrix(dfHere.loc[dfHere['ECE_Pathology']==1,'clinical_Gleason>(3+4)'], dfHere.loc[dfHere['ECE_Pathology']==1,'semantic_MeasurableECE'])\n",
    "\n",
    "cm1/(cm0+cm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(dfTest['clinical_Gleason>(3+4)'], dfTest['semantic_MeasurableECE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfHere = dfTest.copy()\n",
    "cm0 = confusion_matrix(dfHere.loc[dfHere['ECE_Pathology']==0,'clinical_Gleason>(3+4)'], dfHere.loc[dfHere['ECE_Pathology']==0,'semantic_MeasurableECE'])\n",
    "cm1 = confusion_matrix(dfHere.loc[dfHere['ECE_Pathology']==1,'clinical_Gleason>(3+4)'], dfHere.loc[dfHere['ECE_Pathology']==1,'semantic_MeasurableECE'])\n",
    "\n",
    "cm1/(cm0+cm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTrainHere = dfTrain.copy()\n",
    "dfTestHere = dfTest.copy()\n",
    "\n",
    "dfTrainHere['clinical_interaction'] = dfTrainHere['semantic_MeasurableECE']*dfTrainHere['clinical_Gleason>(3+4)']\n",
    "dfTestHere['clinical_interaction'] = dfTestHere['semantic_MeasurableECE']*dfTestHere['clinical_Gleason>(3+4)']\n",
    "\n",
    "# dfTrainHere['clinical_MeasurableECE'] = dfTrainHere['semantic_MeasurableECE']\n",
    "# dfTestHere['clinical_MeasurableECE'] = dfTestHere['semantic_MeasurableECE']\n",
    "\n",
    "# dfTrainHere.drop(['clinical_ProstateVolume', 'clinical_PIRADS>4', 'clinical_PSA'], axis=1, inplace=True)\n",
    "# dfTestHere.drop(['clinical_ProstateVolume', 'clinical_PIRADS>4', 'clinical_PSA'], axis=1, inplace=True)\n",
    "\n",
    "rInt = fitModel(dfTrainHere,\n",
    "               dfTestHere,\n",
    "               pipelineLRridge, \n",
    "               coefDisplayFunction=coefDispFunLRlasso, \n",
    "               keepRegex='clinical|semantic', \n",
    "               dropList=[], #'semantic_MeasurableECE', 'clinical_interaction'],\n",
    "               permutationTest=permutationTest,\n",
    "               jitterTestData=False,\n",
    "               crossValidate=crossValidate)\n",
    "showShapLR(rInt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTrainHere = dfTrain.copy()\n",
    "dfTestHere = dfTest.copy()\n",
    "\n",
    "dfTrainHere['clinical_interaction'] = dfTrainHere['semantic_MeasurableECE']*dfTrainHere['clinical_Gleason>(3+4)']\n",
    "dfTestHere['clinical_interaction'] = dfTestHere['semantic_MeasurableECE']*dfTestHere['clinical_Gleason>(3+4)']\n",
    "\n",
    "rInt = fitModel(dfTrainHere,\n",
    "               dfTestHere,\n",
    "               pipelineLRsimple, \n",
    "               coefDisplayFunction=coefDispFunLRsimple, \n",
    "               keepRegex='clinical_interaction|semantic_MeasurableECE|clinical_Gleason\\>\\(3\\+4\\)|semantic_CapsularContactLength|semantic_IrregularContour|semantic_RetroprostaticAngleOblit|semantic_CapsularDisruption', \n",
    "               dropList=[], #'semantic_MeasurableECE', 'clinical_interaction'],\n",
    "               permutationTest=permutationTest,\n",
    "               jitterTestData=False,\n",
    "               crossValidate=crossValidate)\n",
    "showShapLR(rInt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['clinical_Gleason>(3+4)', 'clinical_ProstateVolume', 'clinical_PSA',\n",
      "       'clinical_PIRADS>4', 'semantic_AnatDev01', 'semantic_AnatDev02',\n",
      "       'semantic_AnatDev03', 'semantic_AnatDev04', 'semantic_MajorLengthIndex',\n",
      "       'semantic_CapsularContactLength', 'semantic_SmoothCapsularBulging',\n",
      "       'semantic_CapsularDisruption', 'semantic_UnsharpMargin',\n",
      "       'semantic_IrregularContour', 'semantic_BlackEstritionPeripFat',\n",
      "       'semantic_RetroprostaticAngleOblit', 'semantic_highsignalT1FS'],\n",
      "      dtype='object')\n",
      "AUCROC   (CV) = 0.893  0.101\n",
      "Accuracy (CV) = 0.831  0.091\n",
      "F1       (CV) = 0.621  0.212\n",
      "\n",
      "AUCROC   (test) = 0.888\n",
      "Accuracy (test) = 0.745\n",
      "F1       (test) = 0.533\n",
      "p-value  (test) = 3e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coeff</th>\n",
       "      <th>Freq</th>\n",
       "      <th>ICC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gleason&gt;(3+4)</td>\n",
       "      <td>0.413728</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CapsularContactLength</td>\n",
       "      <td>0.333424</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.692885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>IrregularContour</td>\n",
       "      <td>0.243177</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.417117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RetroprostaticAngleOblit</td>\n",
       "      <td>0.163890</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.479456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CapsularDisruption</td>\n",
       "      <td>0.074518</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.352134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Feature     Coeff  Freq       ICC\n",
       "0              Gleason>(3+4)  0.413728  1.00         -\n",
       "9      CapsularContactLength  0.333424  1.00  0.692885\n",
       "13          IrregularContour  0.243177  1.00  0.417117\n",
       "15  RetroprostaticAngleOblit  0.163890  1.00  0.479456\n",
       "11        CapsularDisruption  0.074518  0.94  0.352134"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfTrainHere = dfTrain.copy()\n",
    "dfTestHere = dfTest.copy()\n",
    "\n",
    "rInt = fitModel(dfTrainHere,\n",
    "               dfTestHere,\n",
    "               pipelineLRlasso, \n",
    "               coefDisplayFunction=coefDispFunLRlasso, \n",
    "               keepRegex='clinical|semantic', \n",
    "               dropList=['semantic_MeasurableECE'],\n",
    "               permutationTest=permutationTest,\n",
    "               jitterTestData=False,\n",
    "               crossValidate=crossValidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rInt['pipeline']._final_estimator.best_estimator_.fit(rInt['XTrain'], rInt['yTrain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rInt.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rInt['cv_result']['estimator'][0].steps[1][1].best_estimator_.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this version when LR tuning done uing GridSearch\n",
    "def showShapLR2(r, file=None):\n",
    "    standardiser = r['pipeline'].steps[0][1]\n",
    "\n",
    "    # get final estimator and refit to the non-zero coefficients\n",
    "#     estimator = r['pipeline']._final_estimator.best_estimator_.copy()\n",
    "#     coef = \n",
    "#     estimator.fit(r['XTrain'], r['yTrain'])\n",
    "\n",
    "    X = pd.DataFrame(columns=r['XTest'].columns, data=standardiser.transform(r['XTest'].copy()))\n",
    "    X = X.rename(columns=lambda x: x.replace('clinical_',''))\n",
    "    X = X.rename(columns=lambda x: x.replace('semantic_',''))\n",
    "    X = X.rename(columns=lambda x: x.replace('radiomics_',''))\n",
    "    \n",
    "    \n",
    "    explainer = shap.explainers.Linear(r['pipeline']._final_estimator.best_estimator_, X)\n",
    "    shap_values = explainer(X)\n",
    "    max_display = 1 + np.sum(r['pipeline']._final_estimator.best_estimator_.coef_ != 0)\n",
    "    shap.plots.beeswarm(shap_values, max_display=max_display, show=False)\n",
    "\n",
    "    if file is not None:\n",
    "        plt.savefig(file, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showShapLR2(rInt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
